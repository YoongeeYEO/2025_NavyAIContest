{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 AutoGluon GPU 최적화 (수정 버전)\n",
      "🌟 간단한 AutoGluon GPU 파이프라인\n",
      "==================================================\n",
      "📁 데이터 로딩...\n",
      "✅ 데이터 로드 완료: (2678129, 27)\n",
      "📊 전처리 완료: (2678129, 26), 타겟 클래스 2개\n",
      "🚀 수정된 GPU 최적화 AutoGluon 훈련 시작\n",
      "🔍 GPU 상태 확인:\n",
      "PyTorch CUDA 사용 가능: True\n",
      "CUDA 버전: 12.4\n",
      "GPU 개수: 1\n",
      "GPU 0: NVIDIA A100 80GB PCIe MIG 1g.10gb (9.5 GB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.12.7\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #107-Ubuntu SMP Wed Feb 7 13:26:48 UTC 2024\n",
      "CPU Count:          2\n",
      "Memory Avail:       19.27 GB / 24.00 GB (80.3%)\n",
      "Disk Space Avail:   452.73 GB / 511.75 GB (88.5%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 데이터 분할:\n",
      "- 훈련: 2,142,503 행, 26 컬럼\n",
      "- 테스트: 535,626 행\n",
      "📊 문제 유형: binary (2개 클래스)\n",
      "🔧 AutoGluon 설정:\n",
      "- GPU 사용: 1개\n",
      "- CPU 사용: 2개\n",
      "- 시간 제한: 100분\n",
      "- 품질: medium_quality\n",
      "🗑️ 기존 모델 디렉토리 삭제: ./autogluon_gpu_models_fixed\n",
      "💻 기본 하이퍼파라미터 사용\n",
      "\n",
      "⏳ GPU 가속 훈련 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 6000s\n",
      "AutoGluon will save models to \"/home/elicer/ai/autogluon_gpu_models_fixed\"\n",
      "Train Data Rows:    2142503\n",
      "Train Data Columns: 26\n",
      "Label Column:       target\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19734.99 MB\n",
      "\tTrain Data (Original)  Memory Usage: 425.00 MB (2.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['trajectory_duration', 'avg_sog', 'std_sog', 'max_sog', 'min_sog', ...]\n",
      "\t\t('int', [])   :  9 | ['MMSI', 'is_korean_ship', 'num_points', 'sharp_turns', 'num_low_speed_periods', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 17 | ['trajectory_duration', 'avg_sog', 'std_sog', 'max_sog', 'min_sog', ...]\n",
      "\t\t('int', [])       :  4 | ['MMSI', 'num_points', 'num_low_speed_periods', 'num_zone_entries']\n",
      "\t\t('int', ['bool']) :  5 | ['is_korean_ship', 'sharp_turns', 'off_events', 'restricted_zone_flag', 'back_forth_count']\n",
      "\t7.4s = Fit runtime\n",
      "\t26 features in original data used to generate 26 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 353.48 MB (1.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 7.99s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 13 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 3993.67s of the 5992.00s of remaining time.\n",
      "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 19191.06s compared to 5184.9s of available time.\n",
      "\tTime limit exceeded... Skipping KNeighborsUnif_BAG_L1.\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 3982.53s of the 5980.87s of remaining time.\n",
      "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 19537.74s compared to 5170.33s of available time.\n",
      "\tTime limit exceeded... Skipping KNeighborsDist_BAG_L1.\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3971.36s of the 5969.70s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=2, gpus=1, memory=12.64%)\n",
      "\t0.9942\t = Validation score   (accuracy)\n",
      "\t3954.93s\t = Training   runtime\n",
      "\t771.26s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 399.37s of the 1923.89s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.9942\t = Validation score   (accuracy)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting 11 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1923.62s of the 1923.49s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=2, gpus=1, memory=15.64%)\n",
      "\t0.9944\t = Validation score   (accuracy)\n",
      "\t1318.52s\t = Training   runtime\n",
      "\t107.33s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 564.63s of the 564.49s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 16.24% memory usage per fold, 64.96%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=2, gpus=1, memory=16.24%)\n",
      "\t0.9947\t = Validation score   (accuracy)\n",
      "\t534.09s\t = Training   runtime\n",
      "\t49.37s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -11.43s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L2': 1.0}\n",
      "\t0.9947\t = Validation score   (accuracy)\n",
      "\t6.06s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6018.23s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 522.1 rows/s (428501 batch size)\n",
      "Enabling decision threshold calibration (calibrate_decision_threshold='auto', metric is valid, problem_type is 'binary')\n",
      "Subsampling y to 1000000 samples to speedup threshold calibration...\n",
      "Calibrating decision threshold to optimize metric accuracy | Checking 51 thresholds...\n",
      "Calibrating decision threshold via fine-grained search | Checking 38 thresholds...\n",
      "\tBase Threshold: 0.500\t| val: 0.9947\n",
      "\tBest Threshold: 0.500\t| val: 0.9947\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/elicer/ai/autogluon_gpu_models_fixed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU 모드 훈련 완료! (소요 시간: 100.4분)\n",
      "\n",
      "📈 모델 성능 평가\n",
      "🎯 성능 결과:\n",
      "- 정확도: 0.9956\n",
      "- 훈련 시간: 100.4분\n",
      "- 예측 시간: 2197.78초\n",
      "- 예측 속도: 244 샘플/초\n",
      "\n",
      "🏆 상위 모델:\n",
      "  LightGBM_BAG_L2: 0.9947\n",
      "  WeightedEnsemble_L3: 0.9947\n",
      "  LightGBMXT_BAG_L2: 0.9944\n",
      "  LightGBMXT_BAG_L1: 0.9942\n",
      "  WeightedEnsemble_L2: 0.9942\n",
      "\n",
      "==================================================\n",
      "🎉 파이프라인 완료!\n",
      "🎯 최종 정확도: 0.9956\n",
      "⏱️ 총 훈련 시간: 100.4분\n",
      "==================================================\n",
      "\n",
      "🚀 성공! 최종 정확도: 0.9956\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "def check_gpu_status():\n",
    "    \"\"\"GPU 상태 확인\"\"\"\n",
    "    print(\"🔍 GPU 상태 확인:\")\n",
    "    print(f\"PyTorch CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA 버전: {torch.version.cuda}\")\n",
    "        print(f\"GPU 개수: {torch.cuda.device_count()}\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            gpu_name = torch.cuda.get_device_name(i)\n",
    "            memory = torch.cuda.get_device_properties(i).total_memory / 1024**3\n",
    "            print(f\"GPU {i}: {gpu_name} ({memory:.1f} GB)\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"❌ GPU를 사용할 수 없습니다.\")\n",
    "        return False\n",
    "\n",
    "def get_fixed_gpu_hyperparameters():\n",
    "    \"\"\"수정된 GPU 최적화 하이퍼파라미터 (num_cpus 오류 해결)\"\"\"\n",
    "    \n",
    "    # CPU 코어 수 자동 감지\n",
    "    cpu_count = os.cpu_count() or 2\n",
    "    print(f\"감지된 CPU 코어 수: {cpu_count}\")\n",
    "    \n",
    "    gpu_hyperparameters = {\n",
    "        # XGBoost with GPU (num_cpus 제거)\n",
    "        'XGB': [\n",
    "            {\n",
    "                'n_estimators': 300,\n",
    "                'learning_rate': 0.1,\n",
    "                'max_depth': 6,\n",
    "                'tree_method': 'gpu_hist',\n",
    "                'gpu_id': 0,\n",
    "                'objective': 'binary:logistic',\n",
    "                'eval_metric': 'logloss'\n",
    "            },\n",
    "            {\n",
    "                'n_estimators': 500,\n",
    "                'learning_rate': 0.05,\n",
    "                'max_depth': 8,\n",
    "                'tree_method': 'gpu_hist',\n",
    "                'gpu_id': 0,\n",
    "                'objective': 'binary:logistic',\n",
    "                'eval_metric': 'logloss'\n",
    "            }\n",
    "        ],\n",
    "        \n",
    "        # LightGBM with GPU (기본 하이퍼파라미터만 사용)\n",
    "        'GBM': [\n",
    "            {\n",
    "                'num_boost_round': 300,\n",
    "                'learning_rate': 0.1,\n",
    "                'device': 'gpu',\n",
    "                'objective': 'binary'\n",
    "            },\n",
    "            {\n",
    "                'num_boost_round': 500,\n",
    "                'learning_rate': 0.05,\n",
    "                'device': 'gpu',\n",
    "                'objective': 'binary'\n",
    "            }\n",
    "        ],\n",
    "        \n",
    "        # CatBoost with GPU\n",
    "        'CAT': [\n",
    "            {\n",
    "                'iterations': 300,\n",
    "                'learning_rate': 0.1,\n",
    "                'depth': 6,\n",
    "                'task_type': 'GPU',\n",
    "                'devices': '0'\n",
    "            },\n",
    "            {\n",
    "                'iterations': 500,\n",
    "                'learning_rate': 0.05,\n",
    "                'depth': 8,\n",
    "                'task_type': 'GPU',\n",
    "                'devices': '0'\n",
    "            }\n",
    "        ],\n",
    "        \n",
    "        # Neural Network with PyTorch (GPU 최적화)\n",
    "        'NN_TORCH': [\n",
    "            {\n",
    "                'num_epochs': 100,\n",
    "                'learning_rate': 0.01,\n",
    "                'batch_size': 512,\n",
    "                'activation': 'relu',\n",
    "                'dropout_prob': 0.1\n",
    "            },\n",
    "            {\n",
    "                'num_epochs': 200,\n",
    "                'learning_rate': 0.005,\n",
    "                'batch_size': 1024,\n",
    "                'activation': 'relu',\n",
    "                'dropout_prob': 0.2\n",
    "            }\n",
    "        ],\n",
    "        \n",
    "        # Random Forest (CPU, n_jobs 명시적 설정)\n",
    "        'RF': [\n",
    "            {\n",
    "                'n_estimators': 200,\n",
    "                'max_depth': 15,\n",
    "                'n_jobs': cpu_count\n",
    "            },\n",
    "            {\n",
    "                'n_estimators': 300,\n",
    "                'max_depth': 20,\n",
    "                'n_jobs': cpu_count\n",
    "            }\n",
    "        ],\n",
    "        \n",
    "        # Extra Trees (CPU, n_jobs 명시적 설정)\n",
    "        'XT': [\n",
    "            {\n",
    "                'n_estimators': 200,\n",
    "                'max_depth': 15,\n",
    "                'n_jobs': cpu_count\n",
    "            },\n",
    "            {\n",
    "                'n_estimators': 300,\n",
    "                'max_depth': 20,\n",
    "                'n_jobs': cpu_count\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return gpu_hyperparameters\n",
    "\n",
    "def train_autogluon_gpu_fixed(X, y, test_size=0.2, time_limit=600, quality='medium_quality'):\n",
    "    \"\"\"수정된 GPU 최적화 AutoGluon 훈련\"\"\"\n",
    "    print(\"🚀 수정된 GPU 최적화 AutoGluon 훈련 시작\")\n",
    "    \n",
    "    # GPU 상태 확인\n",
    "    gpu_available = check_gpu_status()\n",
    "    \n",
    "    # 데이터 분할\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n📊 데이터 분할:\")\n",
    "    print(f\"- 훈련: {X_train.shape[0]:,} 행, {X_train.shape[1]} 컬럼\")\n",
    "    print(f\"- 테스트: {X_test.shape[0]:,} 행\")\n",
    "    \n",
    "    # 훈련 데이터 준비\n",
    "    train_data = X_train.copy()\n",
    "    train_data['target'] = y_train\n",
    "    \n",
    "    # 문제 유형 결정\n",
    "    n_classes = len(np.unique(y))\n",
    "    problem_type = 'binary' if n_classes == 2 else 'multiclass'\n",
    "    print(f\"📊 문제 유형: {problem_type} ({n_classes}개 클래스)\")\n",
    "    \n",
    "    # CPU 코어 수 명시적 설정 (auto 대신 구체적 숫자)\n",
    "    cpu_count = os.cpu_count() or 2\n",
    "    \n",
    "    # 수정된 ag_args_fit (num_cpus를 구체적 숫자로)\n",
    "    ag_args_fit = {\n",
    "        'num_gpus': 1 if gpu_available else 0,\n",
    "        'num_cpus': cpu_count,  # 'auto' 대신 구체적 숫자\n",
    "        'auto_stack': True\n",
    "    }\n",
    "    \n",
    "    print(f\"🔧 AutoGluon 설정:\")\n",
    "    print(f\"- GPU 사용: {ag_args_fit['num_gpus']}개\")\n",
    "    print(f\"- CPU 사용: {ag_args_fit['num_cpus']}개\")\n",
    "    print(f\"- 시간 제한: {time_limit//60}분\")\n",
    "    print(f\"- 품질: {quality}\")\n",
    "    \n",
    "    # 모델 경로 정리 (기존 모델이 있으면 삭제)\n",
    "    model_path = './autogluon_gpu_models_fixed'\n",
    "    if os.path.exists(model_path):\n",
    "        import shutil\n",
    "        shutil.rmtree(model_path)\n",
    "        print(f\"🗑️ 기존 모델 디렉토리 삭제: {model_path}\")\n",
    "    \n",
    "    # 모델 생성\n",
    "    predictor = TabularPredictor(\n",
    "        label='target',\n",
    "        problem_type=problem_type,\n",
    "        eval_metric='accuracy',\n",
    "        path=model_path,\n",
    "        verbosity=2\n",
    "    )\n",
    "    \n",
    "    # GPU 최적화 하이퍼파라미터 (수정된 버전)\n",
    "    if gpu_available and quality in ['best_quality', 'high_quality']:\n",
    "        hyperparameters = get_fixed_gpu_hyperparameters()\n",
    "        print(\"🔥 GPU 최적화 하이퍼파라미터 사용\")\n",
    "    else:\n",
    "        hyperparameters = 'default'\n",
    "        print(\"💻 기본 하이퍼파라미터 사용\")\n",
    "    \n",
    "    # 모델 훈련\n",
    "    print(f\"\\n⏳ GPU 가속 훈련 시작...\")\n",
    "    start_time = pd.Timestamp.now()\n",
    "    \n",
    "    try:\n",
    "        predictor.fit(\n",
    "            train_data,\n",
    "            time_limit=time_limit,\n",
    "            presets=quality,\n",
    "            hyperparameters=hyperparameters,\n",
    "            ag_args_fit=ag_args_fit,\n",
    "            holdout_frac=0.1,\n",
    "            num_bag_folds=5,  # GPU에서 안정성을 위해 줄임\n",
    "            num_bag_sets=1,   # 단순화\n",
    "            num_stack_levels=1,  # 스태킹 레벨 줄임\n",
    "            verbosity=2,\n",
    "            dynamic_stacking=False  # 동적 스태킹 비활성화로 안정성 확보\n",
    "        )\n",
    "        \n",
    "        end_time = pd.Timestamp.now()\n",
    "        training_time = (end_time - start_time).total_seconds()\n",
    "        print(f\"✅ GPU 모드 훈련 완료! (소요 시간: {training_time/60:.1f}분)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ GPU 모드 실패: {e}\")\n",
    "        print(\"🔄 CPU 모드로 재시도...\")\n",
    "        \n",
    "        # 새로운 predictor 생성 (CPU용)\n",
    "        cpu_model_path = './autogluon_cpu_models_fallback'\n",
    "        if os.path.exists(cpu_model_path):\n",
    "            import shutil\n",
    "            shutil.rmtree(cpu_model_path)\n",
    "        \n",
    "        predictor = TabularPredictor(\n",
    "            label='target',\n",
    "            problem_type=problem_type,\n",
    "            eval_metric='accuracy',\n",
    "            path=cpu_model_path,\n",
    "            verbosity=1\n",
    "        )\n",
    "        \n",
    "        # CPU 전용 설정\n",
    "        cpu_hyperparameters = {\n",
    "            'GBM': {},\n",
    "            'CAT': {},\n",
    "            'XGB': {},\n",
    "            'RF': {'n_jobs': cpu_count},\n",
    "            'XT': {'n_jobs': cpu_count}\n",
    "        }\n",
    "        \n",
    "        predictor.fit(\n",
    "            train_data,\n",
    "            time_limit=time_limit,\n",
    "            presets='medium_quality',\n",
    "            hyperparameters=cpu_hyperparameters,\n",
    "            ag_args_fit={'num_gpus': 0, 'num_cpus': cpu_count},\n",
    "            holdout_frac=0.1,\n",
    "            num_bag_folds=3,\n",
    "            num_stack_levels=1,\n",
    "            verbosity=1,\n",
    "            dynamic_stacking=False\n",
    "        )\n",
    "        \n",
    "        end_time = pd.Timestamp.now()\n",
    "        training_time = (end_time - start_time).total_seconds()\n",
    "        print(f\"✅ CPU 모드 훈련 완료! (소요 시간: {training_time/60:.1f}분)\")\n",
    "    \n",
    "    # GPU 메모리 정리\n",
    "    if gpu_available:\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return predictor, X_test, y_test, training_time\n",
    "\n",
    "def evaluate_model_performance(predictor, X_test, y_test, training_time):\n",
    "    \"\"\"모델 성능 평가\"\"\"\n",
    "    print(f\"\\n📈 모델 성능 평가\")\n",
    "    \n",
    "    try:\n",
    "        # 예측 시간 측정\n",
    "        start_time = pd.Timestamp.now()\n",
    "        y_pred = predictor.predict(X_test)\n",
    "        y_pred_proba = predictor.predict_proba(X_test)\n",
    "        end_time = pd.Timestamp.now()\n",
    "        \n",
    "        prediction_time = (end_time - start_time).total_seconds()\n",
    "        \n",
    "        # 성능 지표\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"🎯 성능 결과:\")\n",
    "        print(f\"- 정확도: {accuracy:.4f}\")\n",
    "        print(f\"- 훈련 시간: {training_time/60:.1f}분\")\n",
    "        print(f\"- 예측 시간: {prediction_time:.2f}초\")\n",
    "        print(f\"- 예측 속도: {len(X_test)/prediction_time:.0f} 샘플/초\")\n",
    "        \n",
    "        # 모델 리더보드\n",
    "        try:\n",
    "            leaderboard = predictor.leaderboard(silent=True)\n",
    "            print(f\"\\n🏆 상위 모델:\")\n",
    "            top_models = leaderboard.head(5)\n",
    "            for idx, row in top_models.iterrows():\n",
    "                model_name = row['model']\n",
    "                score = row['score_val']\n",
    "                print(f\"  {model_name}: {score:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"리더보드 조회 실패: {e}\")\n",
    "            leaderboard = pd.DataFrame()\n",
    "        \n",
    "        return accuracy, y_pred, y_pred_proba, leaderboard\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❗ 성능 평가 중 오류: {e}\")\n",
    "        return 0.0, None, None, pd.DataFrame()\n",
    "\n",
    "def simple_autogluon_gpu(file_path, time_limit=6000, quality='medium_quality'):\n",
    "    \"\"\"간단한 AutoGluon GPU 파이프라인\"\"\"\n",
    "    print(\"🌟 간단한 AutoGluon GPU 파이프라인\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # 데이터 로드\n",
    "        print(\"📁 데이터 로딩...\")\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"✅ 데이터 로드 완료: {df.shape}\")\n",
    "        \n",
    "        # 전처리\n",
    "        X = df.drop('result', axis=1)\n",
    "        y = df['result']\n",
    "        \n",
    "        # 타겟 인코딩 (필요한 경우)\n",
    "        if y.dtype == 'object' or y.dtype == 'bool':\n",
    "            le = LabelEncoder()\n",
    "            y = le.fit_transform(y)\n",
    "        \n",
    "        print(f\"📊 전처리 완료: {X.shape}, 타겟 클래스 {len(np.unique(y))}개\")\n",
    "        \n",
    "        # GPU 최적화 훈련\n",
    "        predictor, X_test, y_test, training_time = train_autogluon_gpu_fixed(\n",
    "            X, y, time_limit=time_limit, quality=quality\n",
    "        )\n",
    "        \n",
    "        # 성능 평가\n",
    "        accuracy, y_pred, y_pred_proba, leaderboard = evaluate_model_performance(\n",
    "            predictor, X_test, y_test, training_time\n",
    "        )\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(f\"🎉 파이프라인 완료!\")\n",
    "        print(f\"🎯 최종 정확도: {accuracy:.4f}\")\n",
    "        print(f\"⏱️ 총 훈련 시간: {training_time/60:.1f}분\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        return predictor, accuracy, leaderboard\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❗ 파이프라인 오류: {e}\")\n",
    "        print(\"💡 기본 CPU 모드를 시도해보세요.\")\n",
    "        return None, 0.0, pd.DataFrame()\n",
    "\n",
    "def basic_cpu_fallback(file_path, time_limit=6000):\n",
    "    \"\"\"기본 CPU 폴백 모드\"\"\"\n",
    "    print(\"💻 기본 CPU 폴백 모드\")\n",
    "    \n",
    "    try:\n",
    "        # 데이터 로드\n",
    "        df = pd.read_csv(file_path)\n",
    "        X = df.drop('result', axis=1)\n",
    "        y = df['result']\n",
    "        \n",
    "        # 타겟 인코딩\n",
    "        if y.dtype == 'object' or y.dtype == 'bool':\n",
    "            le = LabelEncoder()\n",
    "            y = le.fit_transform(y)\n",
    "        \n",
    "        # 데이터 분할\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # 훈련 데이터 준비\n",
    "        train_data = X_train.copy()\n",
    "        train_data['target'] = y_train\n",
    "        \n",
    "        # 간단한 CPU 모델\n",
    "        predictor = TabularPredictor(\n",
    "            label='target',\n",
    "            problem_type='binary' if len(np.unique(y)) == 2 else 'multiclass',\n",
    "            path='./autogluon_simple_cpu',\n",
    "            verbosity=1\n",
    "        )\n",
    "        \n",
    "        predictor.fit(\n",
    "            train_data,\n",
    "            time_limit=time_limit,\n",
    "            presets='optimize_for_deployment',  # 빠른 훈련\n",
    "            verbosity=1\n",
    "        )\n",
    "        \n",
    "        # 예측 및 평가\n",
    "        y_pred = predictor.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"✅ CPU 폴백 완료! 정확도: {accuracy:.4f}\")\n",
    "        \n",
    "        return predictor, accuracy\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❗ CPU 폴백도 실패: {e}\")\n",
    "        return None, 0.0\n",
    "\n",
    "# 사용 예시\n",
    "if __name__ == \"__main__\":\n",
    "    #file_path = '/home/elicer/ai/train/20230601.csv'\n",
    "    file_path = '/home/elicer/ai/train/merged_output.csv'\n",
    "    print(\"🎯 AutoGluon GPU 최적화 (수정 버전)\")\n",
    "    \n",
    "    try:\n",
    "        # GPU 최적화 버전 시도\n",
    "        predictor, accuracy, leaderboard = simple_autogluon_gpu(\n",
    "            file_path=file_path,\n",
    "            time_limit=6000,  # 5분\n",
    "            quality='medium_quality'\n",
    "        )\n",
    "        \n",
    "        if predictor is not None:\n",
    "            print(f\"\\n🚀 성공! 최종 정확도: {accuracy:.4f}\")\n",
    "        else:\n",
    "            raise Exception(\"GPU 모드 실패\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n⚠️ GPU 모드 실패: {e}\")\n",
    "        print(\"🔄 기본 CPU 모드로 전환...\")\n",
    "        \n",
    "        # CPU 폴백\n",
    "        predictor, accuracy = basic_cpu_fallback(file_path, time_limit=6000)\n",
    "        \n",
    "        if predictor is not None:\n",
    "            print(f\"💻 CPU 모드 성공! 정확도: {accuracy:.4f}\")\n",
    "        else:\n",
    "            print(\"❌ 모든 모드 실패\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 AutoGluon GPU 최적화 (수정 버전)\n",
      "\n",
      "🚀 성공! 최종 정확도: 0.9956\n",
      "\n",
      "🔍 외부 테스트 파일 예측 시작\n",
      "✅ 테스트 파일 로드 완료: (6779, 26)\n",
      "✅ 결과 저장 완료: /home/elicer/ai/test2_20240701.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def predict_unlabeled_file(predictor, test_file_path, output_file_path):\n",
    "    \"\"\"외부 테스트 파일에서 예측 결과 생성\"\"\"\n",
    "    print(\"\\n🔍 외부 테스트 파일 예측 시작\")\n",
    "    try:\n",
    "        # 테스트 파일 로드\n",
    "        test_data = pd.read_csv(test_file_path)\n",
    "        print(f\"✅ 테스트 파일 로드 완료: {test_data.shape}\")\n",
    "\n",
    "        # 예측 수행\n",
    "        predictions = predictor.predict(test_data)\n",
    "\n",
    "        # 결과 저장\n",
    "        test_data['result'] = predictions\n",
    "        test_data['result'] = test_data['result'].apply(lambda x: 'TRUE' if x == 1 else 'FALSE')\n",
    "        test_data = test_data[['MMSI', 'result']]\n",
    "        # 결과 파일 저장\n",
    "        test_data.to_csv(output_file_path, index=False)\n",
    "        print(f\"✅ 결과 저장 완료: {output_file_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❗ 테스트 파일 예측 중 오류: {e}\")\n",
    "\n",
    "# 사용 예시\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = '/home/elicer/ai/train/20230601.csv'  # 훈련 데이터 파일 경로\n",
    "    test_file_path = '/home/elicer/ai/20240701.csv'  # 테스트 파일 경로\n",
    "    output_file_path = '/home/elicer/ai/test2_20240701.csv'  # 결과 저장 경로\n",
    "\n",
    "    print(\"🎯 AutoGluon GPU 최적화 (수정 버전)\")\n",
    "\n",
    "    try:\n",
    "        # # GPU 최적화 버전 시도\n",
    "        # predictor, accuracy, leaderboard = simple_autogluon_gpu(\n",
    "        #     file_path=file_path,\n",
    "        #     time_limit=300,  # 5분\n",
    "        #     quality='medium_quality'\n",
    "        # )\n",
    "\n",
    "        if predictor is not None:\n",
    "            print(f\"\\n🚀 성공! 최종 정확도: {accuracy:.4f}\")\n",
    "\n",
    "            # 테스트 파일 예측\n",
    "            predict_unlabeled_file(predictor, test_file_path, output_file_path)\n",
    "        else:\n",
    "            raise Exception(\"GPU 모드 실패\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n⚠️ GPU 모드 실패: {e}\")\n",
    "        print(\"🔄 기본 CPU 모드로 전환...\")\n",
    "\n",
    "        # CPU 폴백\n",
    "        predictor, accuracy = basic_cpu_fallback(file_path, time_limit=6000)\n",
    "\n",
    "        if predictor is not None:\n",
    "            print(f\"💻 CPU 모드 성공! 정확도: {accuracy:.4f}\")\n",
    "\n",
    "            # 테스트 파일 예측\n",
    "            predict_unlabeled_file(predictor, test_file_path, output_file_path)\n",
    "        else:\n",
    "            print(\"❌ 모든 모드 실패\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/home/elicer/ai/test_20240701.csv')\n",
    "output_file_path = '/home/elicer/ai/test_20240701.csv'\n",
    "df = df[['MMSI', 'result']]\n",
    "df['result'] = df['result'].map({True: 'TRUE', False: 'FALSE'})\n",
    "df.to_csv(output_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
