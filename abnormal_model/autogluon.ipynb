{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ AutoGluon GPU ìµœì í™” (ìˆ˜ì • ë²„ì „)\n",
      "ğŸŒŸ ê°„ë‹¨í•œ AutoGluon GPU íŒŒì´í”„ë¼ì¸\n",
      "==================================================\n",
      "ğŸ“ ë°ì´í„° ë¡œë”©...\n",
      "âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: (2678129, 27)\n",
      "ğŸ“Š ì „ì²˜ë¦¬ ì™„ë£Œ: (2678129, 26), íƒ€ê²Ÿ í´ë˜ìŠ¤ 2ê°œ\n",
      "ğŸš€ ìˆ˜ì •ëœ GPU ìµœì í™” AutoGluon í›ˆë ¨ ì‹œì‘\n",
      "ğŸ” GPU ìƒíƒœ í™•ì¸:\n",
      "PyTorch CUDA ì‚¬ìš© ê°€ëŠ¥: True\n",
      "CUDA ë²„ì „: 12.4\n",
      "GPU ê°œìˆ˜: 1\n",
      "GPU 0: NVIDIA A100 80GB PCIe MIG 1g.10gb (9.5 GB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.12.7\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #107-Ubuntu SMP Wed Feb 7 13:26:48 UTC 2024\n",
      "CPU Count:          2\n",
      "Memory Avail:       19.27 GB / 24.00 GB (80.3%)\n",
      "Disk Space Avail:   452.73 GB / 511.75 GB (88.5%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š ë°ì´í„° ë¶„í• :\n",
      "- í›ˆë ¨: 2,142,503 í–‰, 26 ì»¬ëŸ¼\n",
      "- í…ŒìŠ¤íŠ¸: 535,626 í–‰\n",
      "ğŸ“Š ë¬¸ì œ ìœ í˜•: binary (2ê°œ í´ë˜ìŠ¤)\n",
      "ğŸ”§ AutoGluon ì„¤ì •:\n",
      "- GPU ì‚¬ìš©: 1ê°œ\n",
      "- CPU ì‚¬ìš©: 2ê°œ\n",
      "- ì‹œê°„ ì œí•œ: 100ë¶„\n",
      "- í’ˆì§ˆ: medium_quality\n",
      "ğŸ—‘ï¸ ê¸°ì¡´ ëª¨ë¸ ë””ë ‰í† ë¦¬ ì‚­ì œ: ./autogluon_gpu_models_fixed\n",
      "ğŸ’» ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì‚¬ìš©\n",
      "\n",
      "â³ GPU ê°€ì† í›ˆë ¨ ì‹œì‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 6000s\n",
      "AutoGluon will save models to \"/home/elicer/ai/autogluon_gpu_models_fixed\"\n",
      "Train Data Rows:    2142503\n",
      "Train Data Columns: 26\n",
      "Label Column:       target\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19734.99 MB\n",
      "\tTrain Data (Original)  Memory Usage: 425.00 MB (2.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['trajectory_duration', 'avg_sog', 'std_sog', 'max_sog', 'min_sog', ...]\n",
      "\t\t('int', [])   :  9 | ['MMSI', 'is_korean_ship', 'num_points', 'sharp_turns', 'num_low_speed_periods', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 17 | ['trajectory_duration', 'avg_sog', 'std_sog', 'max_sog', 'min_sog', ...]\n",
      "\t\t('int', [])       :  4 | ['MMSI', 'num_points', 'num_low_speed_periods', 'num_zone_entries']\n",
      "\t\t('int', ['bool']) :  5 | ['is_korean_ship', 'sharp_turns', 'off_events', 'restricted_zone_flag', 'back_forth_count']\n",
      "\t7.4s = Fit runtime\n",
      "\t26 features in original data used to generate 26 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 353.48 MB (1.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 7.99s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 13 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 3993.67s of the 5992.00s of remaining time.\n",
      "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 19191.06s compared to 5184.9s of available time.\n",
      "\tTime limit exceeded... Skipping KNeighborsUnif_BAG_L1.\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 3982.53s of the 5980.87s of remaining time.\n",
      "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 19537.74s compared to 5170.33s of available time.\n",
      "\tTime limit exceeded... Skipping KNeighborsDist_BAG_L1.\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3971.36s of the 5969.70s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=2, gpus=1, memory=12.64%)\n",
      "\t0.9942\t = Validation score   (accuracy)\n",
      "\t3954.93s\t = Training   runtime\n",
      "\t771.26s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 399.37s of the 1923.89s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.9942\t = Validation score   (accuracy)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting 11 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1923.62s of the 1923.49s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=2, gpus=1, memory=15.64%)\n",
      "\t0.9944\t = Validation score   (accuracy)\n",
      "\t1318.52s\t = Training   runtime\n",
      "\t107.33s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 564.63s of the 564.49s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 16.24% memory usage per fold, 64.96%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=2, gpus=1, memory=16.24%)\n",
      "\t0.9947\t = Validation score   (accuracy)\n",
      "\t534.09s\t = Training   runtime\n",
      "\t49.37s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -11.43s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L2': 1.0}\n",
      "\t0.9947\t = Validation score   (accuracy)\n",
      "\t6.06s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6018.23s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 522.1 rows/s (428501 batch size)\n",
      "Enabling decision threshold calibration (calibrate_decision_threshold='auto', metric is valid, problem_type is 'binary')\n",
      "Subsampling y to 1000000 samples to speedup threshold calibration...\n",
      "Calibrating decision threshold to optimize metric accuracy | Checking 51 thresholds...\n",
      "Calibrating decision threshold via fine-grained search | Checking 38 thresholds...\n",
      "\tBase Threshold: 0.500\t| val: 0.9947\n",
      "\tBest Threshold: 0.500\t| val: 0.9947\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/elicer/ai/autogluon_gpu_models_fixed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GPU ëª¨ë“œ í›ˆë ¨ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: 100.4ë¶„)\n",
      "\n",
      "ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\n",
      "ğŸ¯ ì„±ëŠ¥ ê²°ê³¼:\n",
      "- ì •í™•ë„: 0.9956\n",
      "- í›ˆë ¨ ì‹œê°„: 100.4ë¶„\n",
      "- ì˜ˆì¸¡ ì‹œê°„: 2197.78ì´ˆ\n",
      "- ì˜ˆì¸¡ ì†ë„: 244 ìƒ˜í”Œ/ì´ˆ\n",
      "\n",
      "ğŸ† ìƒìœ„ ëª¨ë¸:\n",
      "  LightGBM_BAG_L2: 0.9947\n",
      "  WeightedEnsemble_L3: 0.9947\n",
      "  LightGBMXT_BAG_L2: 0.9944\n",
      "  LightGBMXT_BAG_L1: 0.9942\n",
      "  WeightedEnsemble_L2: 0.9942\n",
      "\n",
      "==================================================\n",
      "ğŸ‰ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!\n",
      "ğŸ¯ ìµœì¢… ì •í™•ë„: 0.9956\n",
      "â±ï¸ ì´ í›ˆë ¨ ì‹œê°„: 100.4ë¶„\n",
      "==================================================\n",
      "\n",
      "ğŸš€ ì„±ê³µ! ìµœì¢… ì •í™•ë„: 0.9956\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "def check_gpu_status():\n",
    "    \"\"\"GPU ìƒíƒœ í™•ì¸\"\"\"\n",
    "    print(\"ğŸ” GPU ìƒíƒœ í™•ì¸:\")\n",
    "    print(f\"PyTorch CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA ë²„ì „: {torch.version.cuda}\")\n",
    "        print(f\"GPU ê°œìˆ˜: {torch.cuda.device_count()}\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            gpu_name = torch.cuda.get_device_name(i)\n",
    "            memory = torch.cuda.get_device_properties(i).total_memory / 1024**3\n",
    "            print(f\"GPU {i}: {gpu_name} ({memory:.1f} GB)\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"âŒ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return False\n",
    "\n",
    "def get_fixed_gpu_hyperparameters():\n",
    "    \"\"\"ìˆ˜ì •ëœ GPU ìµœì í™” í•˜ì´í¼íŒŒë¼ë¯¸í„° (num_cpus ì˜¤ë¥˜ í•´ê²°)\"\"\"\n",
    "    \n",
    "    # CPU ì½”ì–´ ìˆ˜ ìë™ ê°ì§€\n",
    "    cpu_count = os.cpu_count() or 2\n",
    "    print(f\"ê°ì§€ëœ CPU ì½”ì–´ ìˆ˜: {cpu_count}\")\n",
    "    \n",
    "    gpu_hyperparameters = {\n",
    "        # XGBoost with GPU (num_cpus ì œê±°)\n",
    "        'XGB': [\n",
    "            {\n",
    "                'n_estimators': 300,\n",
    "                'learning_rate': 0.1,\n",
    "                'max_depth': 6,\n",
    "                'tree_method': 'gpu_hist',\n",
    "                'gpu_id': 0,\n",
    "                'objective': 'binary:logistic',\n",
    "                'eval_metric': 'logloss'\n",
    "            },\n",
    "            {\n",
    "                'n_estimators': 500,\n",
    "                'learning_rate': 0.05,\n",
    "                'max_depth': 8,\n",
    "                'tree_method': 'gpu_hist',\n",
    "                'gpu_id': 0,\n",
    "                'objective': 'binary:logistic',\n",
    "                'eval_metric': 'logloss'\n",
    "            }\n",
    "        ],\n",
    "        \n",
    "        # LightGBM with GPU (ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë§Œ ì‚¬ìš©)\n",
    "        'GBM': [\n",
    "            {\n",
    "                'num_boost_round': 300,\n",
    "                'learning_rate': 0.1,\n",
    "                'device': 'gpu',\n",
    "                'objective': 'binary'\n",
    "            },\n",
    "            {\n",
    "                'num_boost_round': 500,\n",
    "                'learning_rate': 0.05,\n",
    "                'device': 'gpu',\n",
    "                'objective': 'binary'\n",
    "            }\n",
    "        ],\n",
    "        \n",
    "        # CatBoost with GPU\n",
    "        'CAT': [\n",
    "            {\n",
    "                'iterations': 300,\n",
    "                'learning_rate': 0.1,\n",
    "                'depth': 6,\n",
    "                'task_type': 'GPU',\n",
    "                'devices': '0'\n",
    "            },\n",
    "            {\n",
    "                'iterations': 500,\n",
    "                'learning_rate': 0.05,\n",
    "                'depth': 8,\n",
    "                'task_type': 'GPU',\n",
    "                'devices': '0'\n",
    "            }\n",
    "        ],\n",
    "        \n",
    "        # Neural Network with PyTorch (GPU ìµœì í™”)\n",
    "        'NN_TORCH': [\n",
    "            {\n",
    "                'num_epochs': 100,\n",
    "                'learning_rate': 0.01,\n",
    "                'batch_size': 512,\n",
    "                'activation': 'relu',\n",
    "                'dropout_prob': 0.1\n",
    "            },\n",
    "            {\n",
    "                'num_epochs': 200,\n",
    "                'learning_rate': 0.005,\n",
    "                'batch_size': 1024,\n",
    "                'activation': 'relu',\n",
    "                'dropout_prob': 0.2\n",
    "            }\n",
    "        ],\n",
    "        \n",
    "        # Random Forest (CPU, n_jobs ëª…ì‹œì  ì„¤ì •)\n",
    "        'RF': [\n",
    "            {\n",
    "                'n_estimators': 200,\n",
    "                'max_depth': 15,\n",
    "                'n_jobs': cpu_count\n",
    "            },\n",
    "            {\n",
    "                'n_estimators': 300,\n",
    "                'max_depth': 20,\n",
    "                'n_jobs': cpu_count\n",
    "            }\n",
    "        ],\n",
    "        \n",
    "        # Extra Trees (CPU, n_jobs ëª…ì‹œì  ì„¤ì •)\n",
    "        'XT': [\n",
    "            {\n",
    "                'n_estimators': 200,\n",
    "                'max_depth': 15,\n",
    "                'n_jobs': cpu_count\n",
    "            },\n",
    "            {\n",
    "                'n_estimators': 300,\n",
    "                'max_depth': 20,\n",
    "                'n_jobs': cpu_count\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return gpu_hyperparameters\n",
    "\n",
    "def train_autogluon_gpu_fixed(X, y, test_size=0.2, time_limit=600, quality='medium_quality'):\n",
    "    \"\"\"ìˆ˜ì •ëœ GPU ìµœì í™” AutoGluon í›ˆë ¨\"\"\"\n",
    "    print(\"ğŸš€ ìˆ˜ì •ëœ GPU ìµœì í™” AutoGluon í›ˆë ¨ ì‹œì‘\")\n",
    "    \n",
    "    # GPU ìƒíƒœ í™•ì¸\n",
    "    gpu_available = check_gpu_status()\n",
    "    \n",
    "    # ë°ì´í„° ë¶„í• \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ë°ì´í„° ë¶„í• :\")\n",
    "    print(f\"- í›ˆë ¨: {X_train.shape[0]:,} í–‰, {X_train.shape[1]} ì»¬ëŸ¼\")\n",
    "    print(f\"- í…ŒìŠ¤íŠ¸: {X_test.shape[0]:,} í–‰\")\n",
    "    \n",
    "    # í›ˆë ¨ ë°ì´í„° ì¤€ë¹„\n",
    "    train_data = X_train.copy()\n",
    "    train_data['target'] = y_train\n",
    "    \n",
    "    # ë¬¸ì œ ìœ í˜• ê²°ì •\n",
    "    n_classes = len(np.unique(y))\n",
    "    problem_type = 'binary' if n_classes == 2 else 'multiclass'\n",
    "    print(f\"ğŸ“Š ë¬¸ì œ ìœ í˜•: {problem_type} ({n_classes}ê°œ í´ë˜ìŠ¤)\")\n",
    "    \n",
    "    # CPU ì½”ì–´ ìˆ˜ ëª…ì‹œì  ì„¤ì • (auto ëŒ€ì‹  êµ¬ì²´ì  ìˆ«ì)\n",
    "    cpu_count = os.cpu_count() or 2\n",
    "    \n",
    "    # ìˆ˜ì •ëœ ag_args_fit (num_cpusë¥¼ êµ¬ì²´ì  ìˆ«ìë¡œ)\n",
    "    ag_args_fit = {\n",
    "        'num_gpus': 1 if gpu_available else 0,\n",
    "        'num_cpus': cpu_count,  # 'auto' ëŒ€ì‹  êµ¬ì²´ì  ìˆ«ì\n",
    "        'auto_stack': True\n",
    "    }\n",
    "    \n",
    "    print(f\"ğŸ”§ AutoGluon ì„¤ì •:\")\n",
    "    print(f\"- GPU ì‚¬ìš©: {ag_args_fit['num_gpus']}ê°œ\")\n",
    "    print(f\"- CPU ì‚¬ìš©: {ag_args_fit['num_cpus']}ê°œ\")\n",
    "    print(f\"- ì‹œê°„ ì œí•œ: {time_limit//60}ë¶„\")\n",
    "    print(f\"- í’ˆì§ˆ: {quality}\")\n",
    "    \n",
    "    # ëª¨ë¸ ê²½ë¡œ ì •ë¦¬ (ê¸°ì¡´ ëª¨ë¸ì´ ìˆìœ¼ë©´ ì‚­ì œ)\n",
    "    model_path = './autogluon_gpu_models_fixed'\n",
    "    if os.path.exists(model_path):\n",
    "        import shutil\n",
    "        shutil.rmtree(model_path)\n",
    "        print(f\"ğŸ—‘ï¸ ê¸°ì¡´ ëª¨ë¸ ë””ë ‰í† ë¦¬ ì‚­ì œ: {model_path}\")\n",
    "    \n",
    "    # ëª¨ë¸ ìƒì„±\n",
    "    predictor = TabularPredictor(\n",
    "        label='target',\n",
    "        problem_type=problem_type,\n",
    "        eval_metric='accuracy',\n",
    "        path=model_path,\n",
    "        verbosity=2\n",
    "    )\n",
    "    \n",
    "    # GPU ìµœì í™” í•˜ì´í¼íŒŒë¼ë¯¸í„° (ìˆ˜ì •ëœ ë²„ì „)\n",
    "    if gpu_available and quality in ['best_quality', 'high_quality']:\n",
    "        hyperparameters = get_fixed_gpu_hyperparameters()\n",
    "        print(\"ğŸ”¥ GPU ìµœì í™” í•˜ì´í¼íŒŒë¼ë¯¸í„° ì‚¬ìš©\")\n",
    "    else:\n",
    "        hyperparameters = 'default'\n",
    "        print(\"ğŸ’» ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì‚¬ìš©\")\n",
    "    \n",
    "    # ëª¨ë¸ í›ˆë ¨\n",
    "    print(f\"\\nâ³ GPU ê°€ì† í›ˆë ¨ ì‹œì‘...\")\n",
    "    start_time = pd.Timestamp.now()\n",
    "    \n",
    "    try:\n",
    "        predictor.fit(\n",
    "            train_data,\n",
    "            time_limit=time_limit,\n",
    "            presets=quality,\n",
    "            hyperparameters=hyperparameters,\n",
    "            ag_args_fit=ag_args_fit,\n",
    "            holdout_frac=0.1,\n",
    "            num_bag_folds=5,  # GPUì—ì„œ ì•ˆì •ì„±ì„ ìœ„í•´ ì¤„ì„\n",
    "            num_bag_sets=1,   # ë‹¨ìˆœí™”\n",
    "            num_stack_levels=1,  # ìŠ¤íƒœí‚¹ ë ˆë²¨ ì¤„ì„\n",
    "            verbosity=2,\n",
    "            dynamic_stacking=False  # ë™ì  ìŠ¤íƒœí‚¹ ë¹„í™œì„±í™”ë¡œ ì•ˆì •ì„± í™•ë³´\n",
    "        )\n",
    "        \n",
    "        end_time = pd.Timestamp.now()\n",
    "        training_time = (end_time - start_time).total_seconds()\n",
    "        print(f\"âœ… GPU ëª¨ë“œ í›ˆë ¨ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {training_time/60:.1f}ë¶„)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ GPU ëª¨ë“œ ì‹¤íŒ¨: {e}\")\n",
    "        print(\"ğŸ”„ CPU ëª¨ë“œë¡œ ì¬ì‹œë„...\")\n",
    "        \n",
    "        # ìƒˆë¡œìš´ predictor ìƒì„± (CPUìš©)\n",
    "        cpu_model_path = './autogluon_cpu_models_fallback'\n",
    "        if os.path.exists(cpu_model_path):\n",
    "            import shutil\n",
    "            shutil.rmtree(cpu_model_path)\n",
    "        \n",
    "        predictor = TabularPredictor(\n",
    "            label='target',\n",
    "            problem_type=problem_type,\n",
    "            eval_metric='accuracy',\n",
    "            path=cpu_model_path,\n",
    "            verbosity=1\n",
    "        )\n",
    "        \n",
    "        # CPU ì „ìš© ì„¤ì •\n",
    "        cpu_hyperparameters = {\n",
    "            'GBM': {},\n",
    "            'CAT': {},\n",
    "            'XGB': {},\n",
    "            'RF': {'n_jobs': cpu_count},\n",
    "            'XT': {'n_jobs': cpu_count}\n",
    "        }\n",
    "        \n",
    "        predictor.fit(\n",
    "            train_data,\n",
    "            time_limit=time_limit,\n",
    "            presets='medium_quality',\n",
    "            hyperparameters=cpu_hyperparameters,\n",
    "            ag_args_fit={'num_gpus': 0, 'num_cpus': cpu_count},\n",
    "            holdout_frac=0.1,\n",
    "            num_bag_folds=3,\n",
    "            num_stack_levels=1,\n",
    "            verbosity=1,\n",
    "            dynamic_stacking=False\n",
    "        )\n",
    "        \n",
    "        end_time = pd.Timestamp.now()\n",
    "        training_time = (end_time - start_time).total_seconds()\n",
    "        print(f\"âœ… CPU ëª¨ë“œ í›ˆë ¨ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {training_time/60:.1f}ë¶„)\")\n",
    "    \n",
    "    # GPU ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "    if gpu_available:\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return predictor, X_test, y_test, training_time\n",
    "\n",
    "def evaluate_model_performance(predictor, X_test, y_test, training_time):\n",
    "    \"\"\"ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\"\"\"\n",
    "    print(f\"\\nğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\")\n",
    "    \n",
    "    try:\n",
    "        # ì˜ˆì¸¡ ì‹œê°„ ì¸¡ì •\n",
    "        start_time = pd.Timestamp.now()\n",
    "        y_pred = predictor.predict(X_test)\n",
    "        y_pred_proba = predictor.predict_proba(X_test)\n",
    "        end_time = pd.Timestamp.now()\n",
    "        \n",
    "        prediction_time = (end_time - start_time).total_seconds()\n",
    "        \n",
    "        # ì„±ëŠ¥ ì§€í‘œ\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"ğŸ¯ ì„±ëŠ¥ ê²°ê³¼:\")\n",
    "        print(f\"- ì •í™•ë„: {accuracy:.4f}\")\n",
    "        print(f\"- í›ˆë ¨ ì‹œê°„: {training_time/60:.1f}ë¶„\")\n",
    "        print(f\"- ì˜ˆì¸¡ ì‹œê°„: {prediction_time:.2f}ì´ˆ\")\n",
    "        print(f\"- ì˜ˆì¸¡ ì†ë„: {len(X_test)/prediction_time:.0f} ìƒ˜í”Œ/ì´ˆ\")\n",
    "        \n",
    "        # ëª¨ë¸ ë¦¬ë”ë³´ë“œ\n",
    "        try:\n",
    "            leaderboard = predictor.leaderboard(silent=True)\n",
    "            print(f\"\\nğŸ† ìƒìœ„ ëª¨ë¸:\")\n",
    "            top_models = leaderboard.head(5)\n",
    "            for idx, row in top_models.iterrows():\n",
    "                model_name = row['model']\n",
    "                score = row['score_val']\n",
    "                print(f\"  {model_name}: {score:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"ë¦¬ë”ë³´ë“œ ì¡°íšŒ ì‹¤íŒ¨: {e}\")\n",
    "            leaderboard = pd.DataFrame()\n",
    "        \n",
    "        return accuracy, y_pred, y_pred_proba, leaderboard\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"â— ì„±ëŠ¥ í‰ê°€ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "        return 0.0, None, None, pd.DataFrame()\n",
    "\n",
    "def simple_autogluon_gpu(file_path, time_limit=6000, quality='medium_quality'):\n",
    "    \"\"\"ê°„ë‹¨í•œ AutoGluon GPU íŒŒì´í”„ë¼ì¸\"\"\"\n",
    "    print(\"ğŸŒŸ ê°„ë‹¨í•œ AutoGluon GPU íŒŒì´í”„ë¼ì¸\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # ë°ì´í„° ë¡œë“œ\n",
    "        print(\"ğŸ“ ë°ì´í„° ë¡œë”©...\")\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {df.shape}\")\n",
    "        \n",
    "        # ì „ì²˜ë¦¬\n",
    "        X = df.drop('result', axis=1)\n",
    "        y = df['result']\n",
    "        \n",
    "        # íƒ€ê²Ÿ ì¸ì½”ë”© (í•„ìš”í•œ ê²½ìš°)\n",
    "        if y.dtype == 'object' or y.dtype == 'bool':\n",
    "            le = LabelEncoder()\n",
    "            y = le.fit_transform(y)\n",
    "        \n",
    "        print(f\"ğŸ“Š ì „ì²˜ë¦¬ ì™„ë£Œ: {X.shape}, íƒ€ê²Ÿ í´ë˜ìŠ¤ {len(np.unique(y))}ê°œ\")\n",
    "        \n",
    "        # GPU ìµœì í™” í›ˆë ¨\n",
    "        predictor, X_test, y_test, training_time = train_autogluon_gpu_fixed(\n",
    "            X, y, time_limit=time_limit, quality=quality\n",
    "        )\n",
    "        \n",
    "        # ì„±ëŠ¥ í‰ê°€\n",
    "        accuracy, y_pred, y_pred_proba, leaderboard = evaluate_model_performance(\n",
    "            predictor, X_test, y_test, training_time\n",
    "        )\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(f\"ğŸ‰ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!\")\n",
    "        print(f\"ğŸ¯ ìµœì¢… ì •í™•ë„: {accuracy:.4f}\")\n",
    "        print(f\"â±ï¸ ì´ í›ˆë ¨ ì‹œê°„: {training_time/60:.1f}ë¶„\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        return predictor, accuracy, leaderboard\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"â— íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {e}\")\n",
    "        print(\"ğŸ’¡ ê¸°ë³¸ CPU ëª¨ë“œë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.\")\n",
    "        return None, 0.0, pd.DataFrame()\n",
    "\n",
    "def basic_cpu_fallback(file_path, time_limit=6000):\n",
    "    \"\"\"ê¸°ë³¸ CPU í´ë°± ëª¨ë“œ\"\"\"\n",
    "    print(\"ğŸ’» ê¸°ë³¸ CPU í´ë°± ëª¨ë“œ\")\n",
    "    \n",
    "    try:\n",
    "        # ë°ì´í„° ë¡œë“œ\n",
    "        df = pd.read_csv(file_path)\n",
    "        X = df.drop('result', axis=1)\n",
    "        y = df['result']\n",
    "        \n",
    "        # íƒ€ê²Ÿ ì¸ì½”ë”©\n",
    "        if y.dtype == 'object' or y.dtype == 'bool':\n",
    "            le = LabelEncoder()\n",
    "            y = le.fit_transform(y)\n",
    "        \n",
    "        # ë°ì´í„° ë¶„í• \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # í›ˆë ¨ ë°ì´í„° ì¤€ë¹„\n",
    "        train_data = X_train.copy()\n",
    "        train_data['target'] = y_train\n",
    "        \n",
    "        # ê°„ë‹¨í•œ CPU ëª¨ë¸\n",
    "        predictor = TabularPredictor(\n",
    "            label='target',\n",
    "            problem_type='binary' if len(np.unique(y)) == 2 else 'multiclass',\n",
    "            path='./autogluon_simple_cpu',\n",
    "            verbosity=1\n",
    "        )\n",
    "        \n",
    "        predictor.fit(\n",
    "            train_data,\n",
    "            time_limit=time_limit,\n",
    "            presets='optimize_for_deployment',  # ë¹ ë¥¸ í›ˆë ¨\n",
    "            verbosity=1\n",
    "        )\n",
    "        \n",
    "        # ì˜ˆì¸¡ ë° í‰ê°€\n",
    "        y_pred = predictor.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"âœ… CPU í´ë°± ì™„ë£Œ! ì •í™•ë„: {accuracy:.4f}\")\n",
    "        \n",
    "        return predictor, accuracy\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"â— CPU í´ë°±ë„ ì‹¤íŒ¨: {e}\")\n",
    "        return None, 0.0\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "if __name__ == \"__main__\":\n",
    "    #file_path = '/home/elicer/ai/train/20230601.csv'\n",
    "    file_path = '/home/elicer/ai/train/merged_output.csv'\n",
    "    print(\"ğŸ¯ AutoGluon GPU ìµœì í™” (ìˆ˜ì • ë²„ì „)\")\n",
    "    \n",
    "    try:\n",
    "        # GPU ìµœì í™” ë²„ì „ ì‹œë„\n",
    "        predictor, accuracy, leaderboard = simple_autogluon_gpu(\n",
    "            file_path=file_path,\n",
    "            time_limit=6000,  # 5ë¶„\n",
    "            quality='medium_quality'\n",
    "        )\n",
    "        \n",
    "        if predictor is not None:\n",
    "            print(f\"\\nğŸš€ ì„±ê³µ! ìµœì¢… ì •í™•ë„: {accuracy:.4f}\")\n",
    "        else:\n",
    "            raise Exception(\"GPU ëª¨ë“œ ì‹¤íŒ¨\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâš ï¸ GPU ëª¨ë“œ ì‹¤íŒ¨: {e}\")\n",
    "        print(\"ğŸ”„ ê¸°ë³¸ CPU ëª¨ë“œë¡œ ì „í™˜...\")\n",
    "        \n",
    "        # CPU í´ë°±\n",
    "        predictor, accuracy = basic_cpu_fallback(file_path, time_limit=6000)\n",
    "        \n",
    "        if predictor is not None:\n",
    "            print(f\"ğŸ’» CPU ëª¨ë“œ ì„±ê³µ! ì •í™•ë„: {accuracy:.4f}\")\n",
    "        else:\n",
    "            print(\"âŒ ëª¨ë“  ëª¨ë“œ ì‹¤íŒ¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ AutoGluon GPU ìµœì í™” (ìˆ˜ì • ë²„ì „)\n",
      "\n",
      "ğŸš€ ì„±ê³µ! ìµœì¢… ì •í™•ë„: 0.9956\n",
      "\n",
      "ğŸ” ì™¸ë¶€ í…ŒìŠ¤íŠ¸ íŒŒì¼ ì˜ˆì¸¡ ì‹œì‘\n",
      "âœ… í…ŒìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ ì™„ë£Œ: (6779, 26)\n",
      "âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: /home/elicer/ai/test2_20240701.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def predict_unlabeled_file(predictor, test_file_path, output_file_path):\n",
    "    \"\"\"ì™¸ë¶€ í…ŒìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ì˜ˆì¸¡ ê²°ê³¼ ìƒì„±\"\"\"\n",
    "    print(\"\\nğŸ” ì™¸ë¶€ í…ŒìŠ¤íŠ¸ íŒŒì¼ ì˜ˆì¸¡ ì‹œì‘\")\n",
    "    try:\n",
    "        # í…ŒìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ\n",
    "        test_data = pd.read_csv(test_file_path)\n",
    "        print(f\"âœ… í…ŒìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {test_data.shape}\")\n",
    "\n",
    "        # ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "        predictions = predictor.predict(test_data)\n",
    "\n",
    "        # ê²°ê³¼ ì €ì¥\n",
    "        test_data['result'] = predictions\n",
    "        test_data['result'] = test_data['result'].apply(lambda x: 'TRUE' if x == 1 else 'FALSE')\n",
    "        test_data = test_data[['MMSI', 'result']]\n",
    "        # ê²°ê³¼ íŒŒì¼ ì €ì¥\n",
    "        test_data.to_csv(output_file_path, index=False)\n",
    "        print(f\"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"â— í…ŒìŠ¤íŠ¸ íŒŒì¼ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = '/home/elicer/ai/train/20230601.csv'  # í›ˆë ¨ ë°ì´í„° íŒŒì¼ ê²½ë¡œ\n",
    "    test_file_path = '/home/elicer/ai/20240701.csv'  # í…ŒìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ\n",
    "    output_file_path = '/home/elicer/ai/test2_20240701.csv'  # ê²°ê³¼ ì €ì¥ ê²½ë¡œ\n",
    "\n",
    "    print(\"ğŸ¯ AutoGluon GPU ìµœì í™” (ìˆ˜ì • ë²„ì „)\")\n",
    "\n",
    "    try:\n",
    "        # # GPU ìµœì í™” ë²„ì „ ì‹œë„\n",
    "        # predictor, accuracy, leaderboard = simple_autogluon_gpu(\n",
    "        #     file_path=file_path,\n",
    "        #     time_limit=300,  # 5ë¶„\n",
    "        #     quality='medium_quality'\n",
    "        # )\n",
    "\n",
    "        if predictor is not None:\n",
    "            print(f\"\\nğŸš€ ì„±ê³µ! ìµœì¢… ì •í™•ë„: {accuracy:.4f}\")\n",
    "\n",
    "            # í…ŒìŠ¤íŠ¸ íŒŒì¼ ì˜ˆì¸¡\n",
    "            predict_unlabeled_file(predictor, test_file_path, output_file_path)\n",
    "        else:\n",
    "            raise Exception(\"GPU ëª¨ë“œ ì‹¤íŒ¨\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâš ï¸ GPU ëª¨ë“œ ì‹¤íŒ¨: {e}\")\n",
    "        print(\"ğŸ”„ ê¸°ë³¸ CPU ëª¨ë“œë¡œ ì „í™˜...\")\n",
    "\n",
    "        # CPU í´ë°±\n",
    "        predictor, accuracy = basic_cpu_fallback(file_path, time_limit=6000)\n",
    "\n",
    "        if predictor is not None:\n",
    "            print(f\"ğŸ’» CPU ëª¨ë“œ ì„±ê³µ! ì •í™•ë„: {accuracy:.4f}\")\n",
    "\n",
    "            # í…ŒìŠ¤íŠ¸ íŒŒì¼ ì˜ˆì¸¡\n",
    "            predict_unlabeled_file(predictor, test_file_path, output_file_path)\n",
    "        else:\n",
    "            print(\"âŒ ëª¨ë“  ëª¨ë“œ ì‹¤íŒ¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/home/elicer/ai/test_20240701.csv')\n",
    "output_file_path = '/home/elicer/ai/test_20240701.csv'\n",
    "df = df[['MMSI', 'result']]\n",
    "df['result'] = df['result'].map({True: 'TRUE', False: 'FALSE'})\n",
    "df.to_csv(output_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
