{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","mount_file_id":"1kLveDam2KA095L3MhOcMkmi9NRBw6zSD","authorship_tag":"ABX9TyOxpfbekNLQuln5uUZp042E"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"18e6772d23be470dab3f8d702024edba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_59e5c81233d3463782568572a65204ac","IPY_MODEL_24eaa406593f4bbc88e3910da72774a6","IPY_MODEL_e5d659c84a1542d7958e2a2514c711bc"],"layout":"IPY_MODEL_7c8f44500f0a4bb4af2dc33d73ee54db"}},"59e5c81233d3463782568572a65204ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15cf855516634bfb9e187c8c041c9900","placeholder":"​","style":"IPY_MODEL_4385d3273e684d82b7e80e1857569135","value":"Best trial: 32. Best value: 0.980808: 100%"}},"24eaa406593f4bbc88e3910da72774a6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_baf4a1f6b0ff4f5f997159d631a2b45e","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2c559f0eb2e44fd9b5f762d44016dc55","value":50}},"e5d659c84a1542d7958e2a2514c711bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5738b8223be545d584b1ae90ea75bee2","placeholder":"​","style":"IPY_MODEL_61171fc43caf4fca90aabba49dd4fc4d","value":" 50/50 [13:14&lt;00:00, 15.19s/it]"}},"7c8f44500f0a4bb4af2dc33d73ee54db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15cf855516634bfb9e187c8c041c9900":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4385d3273e684d82b7e80e1857569135":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"baf4a1f6b0ff4f5f997159d631a2b45e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c559f0eb2e44fd9b5f762d44016dc55":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5738b8223be545d584b1ae90ea75bee2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61171fc43caf4fca90aabba49dd4fc4d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Qd_xFbeGway","executionInfo":{"status":"ok","timestamp":1748440343527,"user_tz":-540,"elapsed":9269,"user":{"displayName":"YOONGEE","userId":"13265385226373116446"}},"outputId":"6e7d2b83-d89f-4cea-8257-92f7f2ca8d2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m112.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# ===============================\n","# 0-1. 필수 라이브러리 설치\n","# ===============================\n","!pip install lightgbm catboost shap optuna geopandas shapely pyproj fiona pyarrow --quiet\n","!pip install haversine --quiet\n","\n","# ===============================\n","# 0-2. 라이브러리 임포트\n","# ===============================\n","import os, re, glob, warnings, joblib, numpy as np, pandas as pd, geopandas as gpd\n","from datetime import datetime, timedelta\n","import optuna, lightgbm as lgb, xgboost as xgb\n","from catboost import CatBoostClassifier\n","from shapely.geometry import Polygon\n","from shapely import wkt\n","from haversine import haversine as hs\n","from sklearn.model_selection import StratifiedKFold, train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.feature_selection import VarianceThreshold\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_recall_curve\n","from sklearn.ensemble import IsolationForest\n","\n","# 랜덤 시드 고정\n","SEED = 42\n","np.random.seed(SEED)"]},{"cell_type":"code","source":["# ===============================\n","# 1. Google Drive 마운트\n","# ===============================\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G1qRFHNiHjNP","executionInfo":{"status":"ok","timestamp":1748440364027,"user_tz":-540,"elapsed":2499,"user":{"displayName":"YOONGEE","userId":"13265385226373116446"}},"outputId":"550b1580-70de-4160-b68f-d98b72bb5151"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# ===============================\n","# 2. 데이터 디렉토리 및 파일 분할\n","# ===============================\n","DATA_DIR = '/content/drive/MyDrive/25년 해군 AI 경진대회/dataset/의심선박 훈련용 데이터 셋'\n","ZONE_DIR = '/content/drive/MyDrive/25년 해군 AI 경진대회/dataset/구역 데이터'\n","\n","if not os.path.exists(DATA_DIR):\n","    raise FileNotFoundError(f\"데이터 디렉토리를 찾을 수 없습니다: {DATA_DIR}\")\n","if not os.path.exists(ZONE_DIR):\n","    raise FileNotFoundError(f\"구역 디렉토리를 찾을 수 없습니다: {ZONE_DIR}\")\n","\n","csv_files = sorted(glob.glob(os.path.join(DATA_DIR, '*.csv')))\n","ymd = lambda f: datetime.strptime(re.search(r'(\\d{8})', os.path.basename(f)).group(1), '%Y%m%d')\n","file_dates = [(f, ymd(f)) for f in csv_files]\n","file_dates.sort(key=lambda x: x[1])\n","\n","last_date   = file_dates[-1][1]\n","train_start = last_date - timedelta(days=92)\n","train_files = [f for f,d in file_dates if d >= train_start]\n","val_files   = [f for f,d in file_dates if d <  train_start]\n","\n","print(f\"Train files: {len(train_files)} [{os.path.basename(train_files[0])} ~ {os.path.basename(train_files[-1])}]\")\n","print(f\"Val   files: {len(val_files)} [{os.path.basename(val_files[0])} ~ {os.path.basename(val_files[-1])}]\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bOm3nFJbKqlm","executionInfo":{"status":"ok","timestamp":1748440385663,"user_tz":-540,"elapsed":29,"user":{"displayName":"YOONGEE","userId":"13265385226373116446"}},"outputId":"2b009d44-802c-46d8-be03-c9ec58ba85e5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Train files: 93 [20240229.csv ~ 20240531.csv]\n","Val   files: 273 [20230601.csv ~ 20240228.csv]\n"]}]},{"cell_type":"code","source":["# ===============================\n","# 3. 구역(Zone) 데이터 로드 (수정본)\n","# ===============================\n","import glob, warnings, os, re\n","import pandas as pd\n","import geopandas as gpd\n","from shapely.geometry import Polygon\n","\n","# 문자열 정규화 함수\n","def _normalize(s: str) -> str:\n","    return re.sub(r'[\\s_\\-]', '', s.lower())\n","\n","# 컬럼 이름 매핑 헬퍼\n","def find_col(df: pd.DataFrame, patterns, required: bool=True):\n","    pats = [_normalize(p) for p in patterns]\n","    for col in df.columns:\n","        cn = _normalize(col)\n","        if any(cn == p or cn.startswith(p) or p in cn for p in pats):\n","            return col\n","    if required:\n","        raise KeyError(f\"❌ 필수 컬럼 패턴 {patterns} 에 해당하는 열을 찾지 못했습니다.\\n실제 열 목록: {df.columns.tolist()}\")\n","    return None\n","\n","def load_zones(zone_dir: str) -> gpd.GeoDataFrame:\n","    \"\"\"\n","    zone_dir/*.csv 각 파일에서 LAT/LON 컬럼을 찾아\n","    하나의 Polygon 으로 만들고, zone_type에는 파일명(확장자 제외) 설정\n","    \"\"\"\n","    zone_files = glob.glob(os.path.join(zone_dir, '*.csv'))\n","    gdfs = []\n","    for fp in zone_files:\n","        df = pd.read_csv(fp)\n","        try:\n","            lat_col = find_col(df, ['latitude','lat'])\n","            lon_col = find_col(df, ['longitude','lon'])\n","        except KeyError as e:\n","            warnings.warn(f\"⚠️ {os.path.basename(fp)}: 좌표(LAT/LON) 컬럼을 찾지 못해 건너뜁니다. ({e})\")\n","            continue\n","\n","        coords = list(zip(df[lon_col], df[lat_col]))\n","        if len(coords) < 3:\n","            warnings.warn(f\"⚠️ {os.path.basename(fp)}: 좌표가 3개 미만입니다. 건너뜁니다.\")\n","            continue\n","\n","        poly = Polygon(coords)\n","        zone_type = os.path.splitext(os.path.basename(fp))[0]\n","        gdf = gpd.GeoDataFrame(\n","            {'zone_type':[zone_type], 'geometry':[poly]},\n","            crs='EPSG:4326'\n","        )\n","        gdfs.append(gdf)\n","        print(f\"✅ Loaded zone: {zone_type}\")\n","\n","    if not gdfs:\n","        raise RuntimeError(\"❌ 유효한 구역(zone) 데이터를 하나도 불러오지 못했습니다.\")\n","    return pd.concat(gdfs, ignore_index=True)\n","\n","# 호출\n","zones_gdf = load_zones(ZONE_DIR)\n","print(\"Zone types:\", zones_gdf['zone_type'].tolist())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tcCQvXsTKweM","executionInfo":{"status":"ok","timestamp":1748440687961,"user_tz":-540,"elapsed":327,"user":{"displayName":"YOONGEE","userId":"13265385226373116446"}},"outputId":"8bed8bf0-cc76-4b7f-cc3b-f461a4a15938"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Loaded zone: Area_Navy_train\n","✅ Loaded zone: Area_Near_Sea\n","✅ Loaded zone: Area_Restrict_zone\n","✅ Loaded zone: Area_Sea_cable_lv1_poly\n","✅ Loaded zone: Area_Special_restrict_zone_poly\n","✅ Loaded zone: Area_Target_Area\n","Zone types: ['Area_Navy_train', 'Area_Near_Sea', 'Area_Restrict_zone', 'Area_Sea_cable_lv1_poly', 'Area_Special_restrict_zone_poly', 'Area_Target_Area']\n"]}]},{"cell_type":"code","source":["# 구역 상수\n","ANCHOR_ZONE      = 'Area_Near_Sea'\n","SPECIAL_RESTRICT = 'Area_Special_restrict_zone_poly'\n","NAVY_TRAIN       = 'Area_Navy_train'\n","CABLE_ZONE       = 'Area_Sea_cable_lv1_poly'\n","NO_ENTRY_ZONE    = 'Area_Restrict_zone'"],"metadata":{"id":"Eaa_GFtmKz4I","executionInfo":{"status":"ok","timestamp":1748440913018,"user_tz":-540,"elapsed":46,"user":{"displayName":"YOONGEE","userId":"13265385226373116446"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# 2.5. train/validation 파일 리스트 재확인\n","import glob, re\n","from datetime import datetime, timedelta\n","\n","csv_files = sorted(glob.glob(os.path.join(DATA_DIR, '*.csv')))\n","ymd = lambda f: datetime.strptime(re.search(r'(\\d{8})', os.path.basename(f)).group(1), '%Y%m%d')\n","file_dates = [(f, ymd(f)) for f in csv_files]\n","file_dates.sort(key=lambda x: x[1])\n","last_date   = file_dates[-1][1]\n","train_start = last_date - timedelta(days=92)\n","train_files = [f for f, d in file_dates if d >= train_start]\n","val_files   = [f for f, d in file_dates if d <  train_start]\n","print(f\"Train files: {len(train_files)}, Val files: {len(val_files)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5z8Ep-AMMxN5","executionInfo":{"status":"ok","timestamp":1748441150314,"user_tz":-540,"elapsed":20,"user":{"displayName":"YOONGEE","userId":"13265385226373116446"}},"outputId":"44e575b5-8bcb-44b6-dcd8-ca5a44fb78d6"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Train files: 93, Val files: 273\n"]}]},{"cell_type":"code","source":["# 4. 원본 통계 피처 집계 함수 (ver3 그대로)\n","def aggregate_ais(df):\n","    df = df.copy()\n","    df.rename(columns={\n","        find_col(df, ['basedatetime','timestamp','datetime','time']): 'Time',\n","        find_col(df, ['latitude','lat']): 'Latitude',\n","        find_col(df, ['longitude','lon']): 'Longitude',\n","        find_col(df, ['sog','speed']): 'SOG',\n","        find_col(df, ['cog','course']): 'COG',\n","        find_col(df, ['mmsi']): 'MMSI'\n","    }, inplace=True)\n","    df['Time'] = pd.to_datetime(df['Time'], errors='coerce')\n","    df.dropna(subset=['Time','Latitude','Longitude'], inplace=True)\n","    df.sort_values(['MMSI','Time'], inplace=True)\n","    pts = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.Longitude, df.Latitude), crs='EPSG:4326')\n","    pts = gpd.sjoin(pts, zones_gdf[['zone_type','geometry']], how='left', predicate='within')\n","    for z in zones_gdf['zone_type'].unique():\n","        pts[f\"{z}_flag\"] = (pts['zone_type']==z).astype(int)\n","    pts['time_diff'] = pts.groupby('MMSI')['Time'].diff().dt.total_seconds().fillna(0)\n","\n","    def _agg(g):\n","        dur = g['time_diff']\n","        out = {\n","            'lowspd_out_anchor_sec': ((g[f'{ANCHOR_ZONE}_flag']==1)&(g['SOG']<=5)).dot(dur),\n","            'nomove_out_anchor_sec': ((g[f'{ANCHOR_ZONE}_flag']==1)&(g['SOG']==0)).dot(dur),\n","            'ais_off_cnt_out_anchor': int(((g[f'{ANCHOR_ZONE}_flag']==1)&(g['SOG'].isna())).sum()),\n","            'restrict_train_sec': ((g[f'{NAVY_TRAIN}_flag']==1)).dot(dur),\n","            'sharp_turn_cnt': int((g['COG'].diff().abs()>30).sum()),\n","            'cable_lowspd_sec': ((g[f'{CABLE_ZONE}_flag']==1)&(g['SOG']<=5)).dot(dur),\n","            'no_entry_flag': int((g[f'{NO_ENTRY_ZONE}_flag']==1).any()),\n","        }\n","        # zone flag 그대로 가져오기\n","        for z in zones_gdf['zone_type'].unique():\n","            out[f'{z}_flag'] = g[f'{z}_flag'].max()\n","        return pd.Series(out)\n","\n","    agg = pts.groupby('MMSI', group_keys=False).apply(_agg).reset_index()\n","    if 'result' in df.columns:\n","        agg = agg.merge(df[['MMSI','result']].drop_duplicates('MMSI'), on='MMSI', how='left')\n","    return agg\n","\n","def rule_score(r):\n","    score = 0\n","    if r['lowspd_out_anchor_sec']>=3600 or r['nomove_out_anchor_sec']>=3600: score+=.20\n","    if r['ais_off_cnt_out_anchor']>=3:      score+=.15\n","    if r['restrict_train_sec']>=3600:       score+=.20\n","    if r['sharp_turn_cnt']>=1:              score+=.15\n","    if r['cable_lowspd_sec']>=600:          score+=.15\n","    if r['no_entry_flag']==1:               score+=.15\n","    return score*100\n","\n","def build_dataset(file_list):\n","    raw = pd.concat([pd.read_csv(f) for f in file_list], ignore_index=True)\n","    df  = aggregate_ais(raw)\n","    df['rule_score'] = df.apply(rule_score, axis=1)\n","    df['target'] = df['result'].map({'TRUE':1,'True':1,True:1,1:1,'FALSE':0,'False':0,False:0,0:0})\n","    num_cols = df.select_dtypes(include='number').columns\n","    df[num_cols] = df[num_cols].replace([np.inf,-np.inf], np.nan).fillna(0)\n","    return df"],"metadata":{"id":"rXSyUpwFNrKI","executionInfo":{"status":"ok","timestamp":1748441163767,"user_tz":-540,"elapsed":3,"user":{"displayName":"YOONGEE","userId":"13265385226373116446"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# 5. Train/Val 데이터 집계\n","train_df = build_dataset(train_files)\n","val_df   = build_dataset(val_files)\n","print(\"Train:\", train_df.shape, \"Val:\", val_df.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E0uHOT-kNucT","executionInfo":{"status":"ok","timestamp":1748441370495,"user_tz":-540,"elapsed":200084,"user":{"displayName":"YOONGEE","userId":"13265385226373116446"}},"outputId":"52afea8c-90d7-4efd-feb4-e10b78fa806f"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-11-720fbe55179b>:37: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  agg = pts.groupby('MMSI', group_keys=False).apply(_agg).reset_index()\n","<ipython-input-11-720fbe55179b>:37: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  agg = pts.groupby('MMSI', group_keys=False).apply(_agg).reset_index()\n"]},{"output_type":"stream","name":"stdout","text":["Train: (30329, 17) Val: (44155, 17)\n"]}]},{"cell_type":"code","source":["# 6. 추가 파생변수 함수 정의\n","def rename_raw(df):\n","    df = df.copy()\n","    df.rename(columns={\n","        find_col(df,['basedatetime','timestamp','datetime','time']): 'Time',\n","        find_col(df,['latitude','lat']): 'Latitude',\n","        find_col(df,['longitude','lon']): 'Longitude',\n","        find_col(df,['sog','speed']): 'SOG',\n","        find_col(df,['cog','course']): 'COG',\n","        find_col(df,['mmsi']): 'MMSI'\n","    }, inplace=True)\n","    df['Time'] = pd.to_datetime(df['Time'], errors='coerce')\n","    return df[['MMSI','Time','Latitude','Longitude','SOG','COG']]\n","\n","def add_datetime_features(df):\n","    return df.assign(\n","        hour=df['Time'].dt.hour,\n","        is_weekend=(df['Time'].dt.weekday>=5).astype(int)\n","    )[['MMSI','hour','is_weekend']]\n","\n","def add_distance_features(df):\n","    df = df.sort_values(['MMSI','Time'])\n","    df[['lon_prev','lat_prev']] = df.groupby('MMSI')[['Longitude','Latitude']].shift()\n","    df['dist'] = df.apply(\n","        lambda x: hs((x['lat_prev'],x['lon_prev']), (x['Latitude'],x['Longitude'])) if pd.notnull(x['lon_prev']) else 0,\n","        axis=1\n","    )\n","    return df.groupby('MMSI')['dist'].agg(\n","        total_dist='sum', mean_dist='mean', max_dist='max', std_dist='std'\n","    ).reset_index()\n","\n","def add_speed_change_features(df):\n","    df = df.sort_values(['MMSI','Time'])\n","    df['sog_prev'] = df.groupby('MMSI')['SOG'].shift()\n","    df['delta_sog'] = (df['SOG'] - df['sog_prev']).abs().fillna(0)\n","    return df.groupby('MMSI')['delta_sog'].agg(\n","        mean_delta_sog='mean', max_delta_sog='max', std_delta_sog='std'\n","    ).reset_index()\n","\n","def add_stop_event_features(df, stop_thresh=0.5):\n","    df['is_stop'] = (df['SOG']<=stop_thresh).astype(int)\n","    df['time_diff'] = df.groupby('MMSI')['Time'].diff().dt.total_seconds().fillna(0)\n","    df['stop_sec']  = df['is_stop'] * df['time_diff']\n","    return df.groupby('MMSI')['stop_sec'].agg(total_stop_sec='sum').reset_index()\n","\n","def add_anomaly_score_features(df):\n","    num_cols = df.select_dtypes(include='number').columns.drop(['MMSI','target'], errors='ignore')\n","    iso = IsolationForest(n_estimators=50, random_state=SEED)\n","    df['anomaly'] = iso.fit_predict(df[num_cols].fillna(0))\n","    return df.groupby('MMSI')['anomaly'].agg(mean_anomaly='mean', std_anomaly='std').reset_index()"],"metadata":{"id":"UQu0acS5NwEZ","executionInfo":{"status":"ok","timestamp":1748441423165,"user_tz":-540,"elapsed":7,"user":{"displayName":"YOONGEE","userId":"13265385226373116446"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# 7. Raw 데이터 파생 피처 집계\n","raw_train = pd.concat([pd.read_csv(f) for f in train_files], ignore_index=True)\n","raw_val   = pd.concat([pd.read_csv(f) for f in val_files], ignore_index=True)\n","raw_train = rename_raw(raw_train)\n","raw_val   = rename_raw(raw_val)\n","\n","dt_tr   = add_datetime_features(raw_train)\n","dist_tr = add_distance_features(raw_train)\n","sog_tr  = add_speed_change_features(raw_train)\n","stop_tr = add_stop_event_features(raw_train)\n","ano_tr  = add_anomaly_score_features(train_df)\n","\n","dt_val   = add_datetime_features(raw_val)\n","dist_val = add_distance_features(raw_val)\n","sog_val  = add_speed_change_features(raw_val)\n","stop_val = add_stop_event_features(raw_val)\n","ano_val  = add_anomaly_score_features(val_df)"],"metadata":{"id":"YPD_7gv_OB_R","executionInfo":{"status":"ok","timestamp":1748441481256,"user_tz":-540,"elapsed":55123,"user":{"displayName":"YOONGEE","userId":"13265385226373116446"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# 8. 피처 통합 및 전처리\n","train = (train_df\n","         .merge(dt_tr,    on='MMSI', how='left')\n","         .merge(dist_tr,  on='MMSI', how='left')\n","         .merge(sog_tr,   on='MMSI', how='left')\n","         .merge(stop_tr,  on='MMSI', how='left')\n","         .merge(ano_tr,   on='MMSI', how='left'))\n","val   = (val_df\n","         .merge(dt_val,   on='MMSI', how='left')\n","         .merge(dist_val, on='MMSI', how='left')\n","         .merge(sog_val,  on='MMSI', how='left')\n","         .merge(stop_val, on='MMSI', how='left')\n","         .merge(ano_val,  on='MMSI', how='left'))\n","\n","train.fillna(0, inplace=True)\n","val.fillna(0, inplace=True)\n","\n","X_train = train.drop(columns=['MMSI','result','target'])\n","y_train = train['target']\n","X_val   = val.drop(columns=['MMSI','result','target'])\n","y_val   = val['target']\n","\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_val   = scaler.transform(X_val)\n","vt     = VarianceThreshold(threshold=0.01)\n","X_train = vt.fit_transform(X_train)\n","X_val   = vt.transform(X_val)"],"metadata":{"id":"nwECJixCOugA","executionInfo":{"status":"ok","timestamp":1748441556795,"user_tz":-540,"elapsed":4920,"user":{"displayName":"YOONGEE","userId":"13265385226373116446"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# ===============================\n","# 9. Optuna를 이용한 LightGBM 하이퍼파라미터 튜닝 (최종 수정본)\n","# ===============================\n","import lightgbm as lgb\n","import optuna\n","\n","# Pruner 설정 (중간 성능이 나쁘면 빨리 중단)\n","pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5, interval_steps=1)\n","\n","def objective(trial):\n","    param = {\n","        'objective': 'binary',\n","        'metric': 'auc',\n","        'verbosity': -1,\n","        'boosting_type': 'gbdt',\n","        'seed': SEED,\n","        'num_leaves': trial.suggest_int('num_leaves', 16, 64),\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True),\n","        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n","        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n","        'bagging_freq': trial.suggest_int('bagging_freq', 1, 5),\n","    }\n","    dtrain = lgb.Dataset(X_train, label=y_train)\n","\n","    cv_res = lgb.cv(\n","        param,\n","        dtrain,\n","        num_boost_round=200,    # 부스팅 라운드 축소\n","        nfold=3,                # CV fold 축소\n","        stratified=True,\n","        seed=SEED,\n","        callbacks=[\n","            lgb.early_stopping(stopping_rounds=30),  # 조기종료\n","            lgb.log_evaluation(period=0)\n","        ]\n","    )\n","\n","    # metric key 자동 탐색\n","    # 예: 'auc-mean' 혹은 'auc-mean' 등\n","    metric_key = [k for k in cv_res.keys() if 'mean' in k and 'auc' in k.lower()]\n","    if not metric_key:\n","        raise ValueError(f\"No AUC metric in CV result: {cv_res.keys()}\")\n","    return max(cv_res[metric_key[0]])\n","\n","study = optuna.create_study(\n","    direction='maximize',\n","    sampler=optuna.samplers.TPESampler(seed=SEED),\n","    pruner=pruner\n",")\n","study.optimize(objective, n_trials=50, show_progress_bar=True)\n","\n","best_params = study.best_params\n","print(\"Best LightGBM params:\", best_params)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["18e6772d23be470dab3f8d702024edba","59e5c81233d3463782568572a65204ac","24eaa406593f4bbc88e3910da72774a6","e5d659c84a1542d7958e2a2514c711bc","7c8f44500f0a4bb4af2dc33d73ee54db","15cf855516634bfb9e187c8c041c9900","4385d3273e684d82b7e80e1857569135","baf4a1f6b0ff4f5f997159d631a2b45e","2c559f0eb2e44fd9b5f762d44016dc55","5738b8223be545d584b1ae90ea75bee2","61171fc43caf4fca90aabba49dd4fc4d"]},"id":"1XqJGvVCPNMq","executionInfo":{"status":"ok","timestamp":1748442744265,"user_tz":-540,"elapsed":794052,"user":{"displayName":"YOONGEE","userId":"13265385226373116446"}},"outputId":"9ecacc39-c2b1-4e2d-91ce-854813064d61"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2025-05-28 14:19:30,638] A new study created in memory with name: no-name-07f79df8-e73c-4f18-b325-c5d7542d7b06\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18e6772d23be470dab3f8d702024edba"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.965789 + 0.000649236\n","[I 2025-05-28 14:19:47,540] Trial 0 finished with value: 0.965789098540395 and parameters: {'num_leaves': 34, 'learning_rate': 0.07969454818643935, 'feature_fraction': 0.892797576724562, 'bagging_fraction': 0.8394633936788146, 'bagging_freq': 1}. Best is trial 0 with value: 0.965789098540395.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.838713 + 0.000296032\n","[I 2025-05-28 14:20:03,154] Trial 1 finished with value: 0.8387134530309693 and parameters: {'num_leaves': 23, 'learning_rate': 0.0013066739238053278, 'feature_fraction': 0.9464704583099741, 'bagging_fraction': 0.8404460046972835, 'bagging_freq': 4}. Best is trial 0 with value: 0.965789098540395.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.93366 + 0.00116894\n","[I 2025-05-28 14:20:12,647] Trial 2 finished with value: 0.9336601293171208 and parameters: {'num_leaves': 17, 'learning_rate': 0.08706020878304858, 'feature_fraction': 0.9329770563201687, 'bagging_fraction': 0.6849356442713105, 'bagging_freq': 1}. Best is trial 0 with value: 0.965789098540395.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.848972 + 0.000849489\n","[I 2025-05-28 14:20:27,932] Trial 3 finished with value: 0.8489719624327106 and parameters: {'num_leaves': 24, 'learning_rate': 0.0040596116104843075, 'feature_fraction': 0.8099025726528951, 'bagging_fraction': 0.7727780074568463, 'bagging_freq': 2}. Best is trial 0 with value: 0.965789098540395.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.866483 + 0.000689477\n","[I 2025-05-28 14:20:44,501] Trial 4 finished with value: 0.8664832762186178 and parameters: {'num_leaves': 45, 'learning_rate': 0.0019010245319870357, 'feature_fraction': 0.7168578594140873, 'bagging_fraction': 0.7465447373174767, 'bagging_freq': 3}. Best is trial 0 with value: 0.965789098540395.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[199]\tcv_agg's valid auc: 0.874765 + 0.000802306\n","[I 2025-05-28 14:21:01,891] Trial 5 finished with value: 0.8747650237545647 and parameters: {'num_leaves': 54, 'learning_rate': 0.002508115686045232, 'feature_fraction': 0.8056937753654446, 'bagging_fraction': 0.836965827544817, 'bagging_freq': 1}. Best is trial 0 with value: 0.965789098540395.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.868071 + 0.000742281\n","[I 2025-05-28 14:21:19,896] Trial 6 finished with value: 0.8680705563268204 and parameters: {'num_leaves': 45, 'learning_rate': 0.002193048555664369, 'feature_fraction': 0.6260206371941118, 'bagging_fraction': 0.9795542149013333, 'bagging_freq': 5}. Best is trial 0 with value: 0.965789098540395.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.884198 + 0.000822211\n","[I 2025-05-28 14:21:37,877] Trial 7 finished with value: 0.8841981530318653 and parameters: {'num_leaves': 55, 'learning_rate': 0.0040665633135147945, 'feature_fraction': 0.6390688456025535, 'bagging_fraction': 0.8736932106048627, 'bagging_freq': 3}. Best is trial 0 with value: 0.965789098540395.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.859446 + 0.000749419\n","[I 2025-05-28 14:21:54,162] Trial 8 finished with value: 0.859445524729495 and parameters: {'num_leaves': 21, 'learning_rate': 0.009780337016659405, 'feature_fraction': 0.6137554084460873, 'bagging_fraction': 0.9637281608315128, 'bagging_freq': 2}. Best is trial 0 with value: 0.965789098540395.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.876211 + 0.000804586\n","[I 2025-05-28 14:22:09,064] Trial 9 finished with value: 0.8762108490141817 and parameters: {'num_leaves': 48, 'learning_rate': 0.004201672054372531, 'feature_fraction': 0.8080272084711243, 'bagging_fraction': 0.8186841117373118, 'bagging_freq': 1}. Best is trial 0 with value: 0.965789098540395.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.963724 + 0.000500767\n","[I 2025-05-28 14:22:23,115] Trial 10 finished with value: 0.9637242999839116 and parameters: {'num_leaves': 34, 'learning_rate': 0.07340472227986776, 'feature_fraction': 0.8784471213433285, 'bagging_fraction': 0.6071847502459278, 'bagging_freq': 2}. Best is trial 0 with value: 0.965789098540395.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.972256 + 0.000526941\n","[I 2025-05-28 14:22:37,260] Trial 11 finished with value: 0.9722560466942749 and parameters: {'num_leaves': 34, 'learning_rate': 0.09265121459509276, 'feature_fraction': 0.8850176027607805, 'bagging_fraction': 0.6342340273631956, 'bagging_freq': 2}. Best is trial 11 with value: 0.9722560466942749.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.931538 + 0.000859844\n","[I 2025-05-28 14:22:51,991] Trial 12 finished with value: 0.9315378685277921 and parameters: {'num_leaves': 34, 'learning_rate': 0.03559891344492103, 'feature_fraction': 0.8717557266305394, 'bagging_fraction': 0.6207459801787779, 'bagging_freq': 2}. Best is trial 11 with value: 0.9722560466942749.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.910309 + 0.000582033\n","[I 2025-05-28 14:23:05,793] Trial 13 finished with value: 0.9103094760120394 and parameters: {'num_leaves': 32, 'learning_rate': 0.02397622727424073, 'feature_fraction': 0.9986855976446704, 'bagging_fraction': 0.9148886768311731, 'bagging_freq': 1}. Best is trial 11 with value: 0.9722560466942749.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.940857 + 0.000513374\n","[I 2025-05-28 14:23:21,075] Trial 14 finished with value: 0.9408570709919802 and parameters: {'num_leaves': 38, 'learning_rate': 0.03816555624863524, 'feature_fraction': 0.8779015764979625, 'bagging_fraction': 0.7097939893129924, 'bagging_freq': 2}. Best is trial 11 with value: 0.9722560466942749.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.924105 + 0.00110327\n","[I 2025-05-28 14:23:42,722] Trial 15 finished with value: 0.9241054841116414 and parameters: {'num_leaves': 63, 'learning_rate': 0.014756783020618178, 'feature_fraction': 0.7371197153065265, 'bagging_fraction': 0.6684815593910434, 'bagging_freq': 4}. Best is trial 11 with value: 0.9722560466942749.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.943285 + 0.000223994\n","[I 2025-05-28 14:23:52,882] Trial 16 finished with value: 0.9432854292520932 and parameters: {'num_leaves': 30, 'learning_rate': 0.054304703422290296, 'feature_fraction': 0.9267237447713319, 'bagging_fraction': 0.8969185264404375, 'bagging_freq': 1}. Best is trial 11 with value: 0.9722560466942749.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.978722 + 0.000283862\n","[I 2025-05-28 14:24:06,768] Trial 17 finished with value: 0.9787219182815315 and parameters: {'num_leaves': 39, 'learning_rate': 0.09403887845681812, 'feature_fraction': 0.986135178426182, 'bagging_fraction': 0.768475721362577, 'bagging_freq': 3}. Best is trial 17 with value: 0.9787219182815315.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.90963 + 0.000616492\n","[I 2025-05-28 14:24:24,935] Trial 18 finished with value: 0.90963024179886 and parameters: {'num_leaves': 42, 'learning_rate': 0.017048154263939116, 'feature_fraction': 0.992329151876532, 'bagging_fraction': 0.7539871612489546, 'bagging_freq': 4}. Best is trial 17 with value: 0.9787219182815315.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.932848 + 0.00083065\n","[I 2025-05-28 14:24:38,393] Trial 19 finished with value: 0.9328479558543451 and parameters: {'num_leaves': 28, 'learning_rate': 0.04673925448215453, 'feature_fraction': 0.9440750252523374, 'bagging_fraction': 0.651129729713056, 'bagging_freq': 3}. Best is trial 17 with value: 0.9787219182815315.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.880691 + 0.000824789\n","[I 2025-05-28 14:25:01,824] Trial 20 finished with value: 0.8806906355595662 and parameters: {'num_leaves': 40, 'learning_rate': 0.008478772686135195, 'feature_fraction': 0.8435610989328606, 'bagging_fraction': 0.7271016311894583, 'bagging_freq': 3}. Best is trial 17 with value: 0.9787219182815315.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.977017 + 0.00075859\n","[I 2025-05-28 14:25:16,606] Trial 21 finished with value: 0.9770170729815061 and parameters: {'num_leaves': 37, 'learning_rate': 0.09686752199721554, 'feature_fraction': 0.9196154753386481, 'bagging_fraction': 0.7911302960155628, 'bagging_freq': 2}. Best is trial 17 with value: 0.9787219182815315.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.979479 + 0.000322349\n","[I 2025-05-28 14:25:31,035] Trial 22 finished with value: 0.979479091374628 and parameters: {'num_leaves': 40, 'learning_rate': 0.09426503497947172, 'feature_fraction': 0.963764239766356, 'bagging_fraction': 0.7881665427243371, 'bagging_freq': 3}. Best is trial 22 with value: 0.979479091374628.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.970822 + 0.000360339\n","[I 2025-05-28 14:25:46,232] Trial 23 finished with value: 0.9708224103575066 and parameters: {'num_leaves': 50, 'learning_rate': 0.05675034709322179, 'feature_fraction': 0.9645495208601615, 'bagging_fraction': 0.7969764629577201, 'bagging_freq': 4}. Best is trial 22 with value: 0.979479091374628.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.979573 + 0.000396561\n","[I 2025-05-28 14:25:59,973] Trial 24 finished with value: 0.9795734348636813 and parameters: {'num_leaves': 39, 'learning_rate': 0.09880513008876501, 'feature_fraction': 0.9721108306850282, 'bagging_fraction': 0.7825903413146867, 'bagging_freq': 3}. Best is trial 24 with value: 0.9795734348636813.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.926886 + 0.000611859\n","[I 2025-05-28 14:26:15,437] Trial 25 finished with value: 0.9268860805990079 and parameters: {'num_leaves': 42, 'learning_rate': 0.02517182053121176, 'feature_fraction': 0.97239126287748, 'bagging_fraction': 0.6967016272441023, 'bagging_freq': 3}. Best is trial 24 with value: 0.9795734348636813.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.944478 + 0.000857666\n","[I 2025-05-28 14:26:27,942] Trial 26 finished with value: 0.9444784397487376 and parameters: {'num_leaves': 27, 'learning_rate': 0.06333734844923058, 'feature_fraction': 0.9665967788837784, 'bagging_fraction': 0.7670693179696426, 'bagging_freq': 5}. Best is trial 24 with value: 0.9795734348636813.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.950378 + 0.000941374\n","[I 2025-05-28 14:26:44,631] Trial 27 finished with value: 0.9503782288482571 and parameters: {'num_leaves': 51, 'learning_rate': 0.03394758854006047, 'feature_fraction': 0.7393418588324325, 'bagging_fraction': 0.7409537155025636, 'bagging_freq': 3}. Best is trial 24 with value: 0.9795734348636813.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.931461 + 0.000540709\n","[I 2025-05-28 14:27:01,720] Trial 28 finished with value: 0.931460511139594 and parameters: {'num_leaves': 45, 'learning_rate': 0.025728681351727022, 'feature_fraction': 0.9984901537620982, 'bagging_fraction': 0.8085612137164336, 'bagging_freq': 4}. Best is trial 24 with value: 0.9795734348636813.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.965239 + 0.000855307\n","[I 2025-05-28 14:27:18,888] Trial 29 finished with value: 0.9652389001997298 and parameters: {'num_leaves': 37, 'learning_rate': 0.0714548532188248, 'feature_fraction': 0.9100513575667756, 'bagging_fraction': 0.8400521571702475, 'bagging_freq': 3}. Best is trial 24 with value: 0.9795734348636813.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.970285 + 0.0011686\n","[I 2025-05-28 14:27:36,156] Trial 30 finished with value: 0.970285270266114 and parameters: {'num_leaves': 62, 'learning_rate': 0.0438917528499676, 'feature_fraction': 0.8383093274704897, 'bagging_fraction': 0.8615404903865911, 'bagging_freq': 3}. Best is trial 24 with value: 0.9795734348636813.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.975763 + 7.41494e-05\n","[I 2025-05-28 14:27:51,573] Trial 31 finished with value: 0.975762509240575 and parameters: {'num_leaves': 38, 'learning_rate': 0.09278172015554578, 'feature_fraction': 0.9044793283943926, 'bagging_fraction': 0.7967786541901849, 'bagging_freq': 2}. Best is trial 24 with value: 0.9795734348636813.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.980808 + 0.000621197\n","[I 2025-05-28 14:28:06,417] Trial 32 finished with value: 0.9808079636507432 and parameters: {'num_leaves': 41, 'learning_rate': 0.09778373869587623, 'feature_fraction': 0.9614227850273019, 'bagging_fraction': 0.7922185543876696, 'bagging_freq': 3}. Best is trial 32 with value: 0.9808079636507432.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.968552 + 0.000322422\n","[I 2025-05-28 14:28:21,706] Trial 33 finished with value: 0.968551585552541 and parameters: {'num_leaves': 42, 'learning_rate': 0.065434808571213, 'feature_fraction': 0.9581005713250901, 'bagging_fraction': 0.7724109867526423, 'bagging_freq': 3}. Best is trial 32 with value: 0.9808079636507432.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.978493 + 0.000640718\n","[I 2025-05-28 14:28:36,506] Trial 34 finished with value: 0.978492657407995 and parameters: {'num_leaves': 47, 'learning_rate': 0.07681585545072153, 'feature_fraction': 0.9412528864710112, 'bagging_fraction': 0.7225928582981258, 'bagging_freq': 4}. Best is trial 32 with value: 0.9808079636507432.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.980228 + 0.000210536\n","[I 2025-05-28 14:28:52,102] Trial 35 finished with value: 0.9802281830976102 and parameters: {'num_leaves': 41, 'learning_rate': 0.09669698225931558, 'feature_fraction': 0.9761476111118731, 'bagging_fraction': 0.8171631481234655, 'bagging_freq': 4}. Best is trial 32 with value: 0.9808079636507432.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.960011 + 0.00131903\n","[I 2025-05-28 14:29:16,680] Trial 36 finished with value: 0.9600110483445827 and parameters: {'num_leaves': 43, 'learning_rate': 0.05227778158848468, 'feature_fraction': 0.9392582333995122, 'bagging_fraction': 0.8218248538077314, 'bagging_freq': 4}. Best is trial 32 with value: 0.9808079636507432.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[199]\tcv_agg's valid auc: 0.866381 + 0.000994069\n","[I 2025-05-28 14:29:41,491] Trial 37 finished with value: 0.8663807605318169 and parameters: {'num_leaves': 51, 'learning_rate': 0.0010433696140601197, 'feature_fraction': 0.8434245763681608, 'bagging_fraction': 0.8631029932167398, 'bagging_freq': 5}. Best is trial 32 with value: 0.9808079636507432.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.890229 + 0.000759966\n","[I 2025-05-28 14:30:02,263] Trial 38 finished with value: 0.8902287186279926 and parameters: {'num_leaves': 56, 'learning_rate': 0.006379698120168484, 'feature_fraction': 0.7759189174539101, 'bagging_fraction': 0.890254812408873, 'bagging_freq': 4}. Best is trial 32 with value: 0.9808079636507432.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.883297 + 0.00136622\n","[I 2025-05-28 14:30:15,607] Trial 39 finished with value: 0.8832972759358709 and parameters: {'num_leaves': 16, 'learning_rate': 0.030078339207345935, 'feature_fraction': 0.9732163378158288, 'bagging_fraction': 0.8374119722881023, 'bagging_freq': 4}. Best is trial 32 with value: 0.9808079636507432.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.958614 + 0.00068004\n","[I 2025-05-28 14:30:31,893] Trial 40 finished with value: 0.9586138667166266 and parameters: {'num_leaves': 48, 'learning_rate': 0.04497941644251741, 'feature_fraction': 0.6892726254813402, 'bagging_fraction': 0.9354044189121318, 'bagging_freq': 3}. Best is trial 32 with value: 0.9808079636507432.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.973639 + 6.74644e-05\n","[I 2025-05-28 14:30:46,492] Trial 41 finished with value: 0.9736392789848911 and parameters: {'num_leaves': 40, 'learning_rate': 0.07897475114566661, 'feature_fraction': 0.9808171308306978, 'bagging_fraction': 0.7801835944852071, 'bagging_freq': 3}. Best is trial 32 with value: 0.9808079636507432.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.974905 + 0.000509891\n","[I 2025-05-28 14:31:00,627] Trial 42 finished with value: 0.9749048801525358 and parameters: {'num_leaves': 37, 'learning_rate': 0.09033594365841925, 'feature_fraction': 0.9463460767357392, 'bagging_fraction': 0.7599940429692251, 'bagging_freq': 3}. Best is trial 32 with value: 0.9808079636507432.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.971739 + 0.000642776\n","[I 2025-05-28 14:31:15,858] Trial 43 finished with value: 0.971738882966001 and parameters: {'num_leaves': 44, 'learning_rate': 0.06733843081065995, 'feature_fraction': 0.9844517176150719, 'bagging_fraction': 0.739852977901466, 'bagging_freq': 3}. Best is trial 32 with value: 0.9808079636507432.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.977934 + 0.000681772\n","[I 2025-05-28 14:31:30,000] Trial 44 finished with value: 0.9779336324092395 and parameters: {'num_leaves': 39, 'learning_rate': 0.09425854752127413, 'feature_fraction': 0.9568445377608317, 'bagging_fraction': 0.8230634126081035, 'bagging_freq': 4}. Best is trial 32 with value: 0.9808079636507432.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.956463 + 0.00110693\n","[I 2025-05-28 14:31:44,359] Trial 45 finished with value: 0.956463132615914 and parameters: {'num_leaves': 35, 'learning_rate': 0.060620020008639475, 'feature_fraction': 0.8995936683957844, 'bagging_fraction': 0.7829692624026529, 'bagging_freq': 3}. Best is trial 32 with value: 0.9808079636507432.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.971336 + 0.00133285\n","[I 2025-05-28 14:31:58,819] Trial 46 finished with value: 0.9713363050372306 and parameters: {'num_leaves': 32, 'learning_rate': 0.09842423500451282, 'feature_fraction': 0.9273441322591016, 'bagging_fraction': 0.8046850421483865, 'bagging_freq': 2}. Best is trial 32 with value: 0.9808079636507432.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.976829 + 0.000414675\n","[I 2025-05-28 14:32:13,881] Trial 47 finished with value: 0.9768285696068073 and parameters: {'num_leaves': 46, 'learning_rate': 0.0747275538109423, 'feature_fraction': 0.980546770497085, 'bagging_fraction': 0.8516573998549044, 'bagging_freq': 3}. Best is trial 32 with value: 0.9808079636507432.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.954717 + 0.000704178\n","[I 2025-05-28 14:32:28,919] Trial 48 finished with value: 0.9547173580318266 and parameters: {'num_leaves': 41, 'learning_rate': 0.04827648093425853, 'feature_fraction': 0.863866521497914, 'bagging_fraction': 0.8208019535890232, 'bagging_freq': 5}. Best is trial 32 with value: 0.9808079636507432.\n","Training until validation scores don't improve for 30 rounds\n","Did not meet early stopping. Best iteration is:\n","[200]\tcv_agg's valid auc: 0.901621 + 0.000797756\n","[I 2025-05-28 14:32:44,694] Trial 49 finished with value: 0.901620920372177 and parameters: {'num_leaves': 35, 'learning_rate': 0.017496390676966466, 'feature_fraction': 0.9149551923622707, 'bagging_fraction': 0.6880502536411812, 'bagging_freq': 2}. Best is trial 32 with value: 0.9808079636507432.\n","Best LightGBM params: {'num_leaves': 41, 'learning_rate': 0.09778373869587623, 'feature_fraction': 0.9614227850273019, 'bagging_fraction': 0.7922185543876696, 'bagging_freq': 3}\n"]}]},{"cell_type":"code","source":["from xgboost import XGBClassifier, callback as xgb_callback\n","\n","# 10. 5-Fold CV 스태킹 앙상블 (수정본)\n","NFOLDS = 5\n","skf    = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=SEED)\n","oof    = np.zeros(len(X_train))\n","val_oof= np.zeros(len(X_val))\n","base_models = []\n","\n","for fold, (tr_idx, va_idx) in enumerate(skf.split(X_train, y_train)):\n","    X_tr, y_tr = X_train[tr_idx], y_train.iloc[tr_idx]\n","    X_va, y_va = X_train[va_idx], y_train.iloc[va_idx]\n","\n","    # LightGBM\n","    lgbm = lgb.LGBMClassifier(**best_params, n_estimators=1000)\n","    lgbm.fit(\n","        X_tr, y_tr,\n","        eval_set=[(X_va, y_va)],\n","        eval_metric='auc',\n","        callbacks=[\n","            lgb.early_stopping(stopping_rounds=50),\n","            lgb.log_evaluation(period=0)\n","        ]\n","    )\n","    oof[va_idx] += lgbm.predict_proba(X_va)[:,1]\n","    val_oof    += lgbm.predict_proba(X_val)[:,1] / NFOLDS\n","    base_models.append(('lgbm_fold%d' % fold, lgbm))\n","\n","    # XGBoost (unchanged)\n","    xgbm = xgb.XGBClassifier(\n","    use_label_encoder=False,\n","    eval_metric='auc',\n","    seed=SEED,\n","    n_estimators=200\n",")\n","# eval_set, early_stopping 제거\n","    xgbm.fit(X_tr, y_tr)\n","\n","    oof[va_idx] += xgbm.predict_proba(X_va)[:,1]\n","    val_oof    += xgbm.predict_proba(X_val)[:,1] / NFOLDS\n","    base_models.append((f'xgbm_fold{fold}', xgbm))\n","\n","    # CatBoost (unchanged)\n","    cb = CatBoostClassifier(verbose=0, random_seed=SEED)\n","    cb.fit(\n","        X_tr, y_tr,\n","        eval_set=(X_va, y_va),\n","        early_stopping_rounds=50\n","    )\n","    oof[va_idx] += cb.predict_proba(X_va)[:,1]\n","    val_oof    += cb.predict_proba(X_val)[:,1] / NFOLDS\n","    base_models.append(('catb_fold%d' % fold, cb))\n","\n","oof    /= 3\n","val_oof/= 3\n","\n","stack_X     = oof.reshape(-1,1)\n","stack_val_X = val_oof.reshape(-1,1)\n","meta = LogisticRegression()\n","meta.fit(stack_X, y_train)\n","final_val = meta.predict_proba(stack_val_X)[:,1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SNtbiYXFPRJm","executionInfo":{"status":"ok","timestamp":1748443786131,"user_tz":-540,"elapsed":413715,"user":{"displayName":"YOONGEE","userId":"13265385226373116446"}},"outputId":"fe2046a7-0de4-4416-b6c9-eb338f19a8ff"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Training until validation scores don't improve for 50 rounds\n","Did not meet early stopping. Best iteration is:\n","[1000]\tvalid_0's auc: 0.999599\tvalid_0's binary_logloss: 0.0396735\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:43:56] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Training until validation scores don't improve for 50 rounds\n","Did not meet early stopping. Best iteration is:\n","[1000]\tvalid_0's auc: 0.999525\tvalid_0's binary_logloss: 0.0392639\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:45:18] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Training until validation scores don't improve for 50 rounds\n","Did not meet early stopping. Best iteration is:\n","[1000]\tvalid_0's auc: 0.999494\tvalid_0's binary_logloss: 0.0401214\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:46:39] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Training until validation scores don't improve for 50 rounds\n","Did not meet early stopping. Best iteration is:\n","[1000]\tvalid_0's auc: 0.999467\tvalid_0's binary_logloss: 0.0397791\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:48:01] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Training until validation scores don't improve for 50 rounds\n","Did not meet early stopping. Best iteration is:\n","[1000]\tvalid_0's auc: 0.999537\tvalid_0's binary_logloss: 0.0395972\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:49:25] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]}]},{"cell_type":"code","source":["# 11. Threshold 최적화 (F1 기준)\n","prec, rec, thr = precision_recall_curve(y_val, final_val)\n","f1s = 2*prec*rec/(prec+rec+1e-9)\n","best_idx = np.argmax(f1s)\n","best_th  = thr[best_idx]\n","print(f\"Optimal threshold (F1): {best_th:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LnCtWMmnR7So","executionInfo":{"status":"ok","timestamp":1748443869467,"user_tz":-540,"elapsed":157,"user":{"displayName":"YOONGEE","userId":"13265385226373116446"}},"outputId":"f3820e6d-9828-4cdd-c24c-cb340463208b"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Optimal threshold (F1): 0.0502\n"]}]},{"cell_type":"code","source":["# 12. 파이프라인 저장\n","pipeline = {\n","    'scaler':     scaler,\n","    'var_thresh': vt,\n","    'base_models': base_models,\n","    'meta_model':  meta,\n","    'threshold':   best_th\n","}\n","joblib.dump(pipeline, '/content/drive/MyDrive/25년 해군 AI 경진대회/model_result/ver4_pipeline.pkl')\n","print(\"Saved pipeline to ver4_pipeline.pkl\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eIHswLTOR9Nb","executionInfo":{"status":"ok","timestamp":1748443878496,"user_tz":-540,"elapsed":1342,"user":{"displayName":"YOONGEE","userId":"13265385226373116446"}},"outputId":"77be4088-9ce3-472b-9726-192ecb9c77f5"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved pipeline to ver4_pipeline.pkl\n"]}]},{"cell_type":"code","source":["import os\n","import joblib\n","import pandas as pd\n","import numpy as np\n","\n","# 1. 경로 설정\n","DATA_DIR        = '/content/drive/MyDrive/25년 해군 AI 경진대회/dataset/의심선박 훈련용 데이터 셋'\n","PIPELINE_PATH   = '/content/drive/MyDrive/25년 해군 AI 경진대회/model_result/ver4_pipeline.pkl'\n","NEW_FILE        = '/content/20240701(1번문제).csv'\n","SUBMISSION_FILE = '/content/drive/MyDrive/25년 해군 AI 경진대회/model_result/submission_ver4model.csv'\n","\n","# 2. 파이프라인 로드\n","pipeline     = joblib.load(PIPELINE_PATH)\n","scaler       = pipeline['scaler']\n","var_thresh   = pipeline['var_thresh']\n","base_models  = pipeline['base_models']\n","meta_model   = pipeline['meta_model']\n","threshold    = pipeline['threshold']\n","\n","# 3. 새 AIS 데이터 읽기\n","raw_new = pd.read_csv(NEW_FILE)\n","\n","# 4. 피처 엔지니어링 (이미 정의된 함수 재사용)\n","agg       = aggregate_ais(raw_new)\n","agg['rule_score'] = agg.apply(rule_score, axis=1)\n","\n","raw_ren   = rename_raw(raw_new)\n","dt_feat   = add_datetime_features(raw_ren)\n","dist_feat = add_distance_features(raw_ren)\n","sog_feat  = add_speed_change_features(raw_ren)\n","stop_feat = add_stop_event_features(raw_ren)\n","ano_feat  = add_anomaly_score_features(agg)\n","\n","# 5. 피처 병합 — 반드시 aggregate_ais()가 뽑아낸 원본 피처(플래그 포함)와 rule_score를 모두 포함\n","features = (\n","    agg\n","    .merge(dt_feat,    on='MMSI', how='left')\n","    .merge(dist_feat,  on='MMSI', how='left')\n","    .merge(sog_feat,   on='MMSI', how='left')\n","    .merge(stop_feat,  on='MMSI', how='left')\n","    .merge(ano_feat,   on='MMSI', how='left')\n",")\n","# agg already contains lowspd_out_anchor_sec, nomove_out_anchor_sec,\n","# ais_off_cnt_out_anchor, restrict_train_sec, sharp_turn_cnt,\n","# cable_lowspd_sec, no_entry_flag, plus all \"{zone}_flag\" cols, and rule_score.\n","\n","# 6. 모델 입력 배열 준비 — DataFrame이 아니라 numpy array로 변환하여\n","#    scaler.transform 시 feature‐name checking을 우회합니다.\n","X = features.drop(columns=['MMSI']).fillna(0).to_numpy()\n","\n","# 7. 스케일링 & 분산 임계치 제거\n","X_scaled = scaler.transform(X)\n","X_sel    = var_thresh.transform(X_scaled)\n","\n","# 8. 예측 (Base 모델 앙상블 → Meta 모델 → Threshold)\n","pred_sum = np.zeros(X_sel.shape[0])\n","for _, model in base_models:\n","    pred_sum += model.predict_proba(X_sel)[:,1]\n","pred_avg     = pred_sum / len(base_models)\n","meta_input   = pred_avg.reshape(-1,1)\n","meta_pred    = meta_model.predict_proba(meta_input)[:,1]\n","results_bool = meta_pred >= threshold\n","results_str  = np.where(results_bool, 'TRUE', 'FALSE')\n","\n","# 9. 제출용 CSV 생성\n","submission = pd.DataFrame({\n","    'MMSI':   features['MMSI'],\n","    'result': results_str\n","})\n","submission.to_csv(SUBMISSION_FILE, index=False)\n","print(\"✅ Submission saved to\", SUBMISSION_FILE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1kyhecwgYE5I","executionInfo":{"status":"ok","timestamp":1748445785343,"user_tz":-540,"elapsed":16961,"user":{"displayName":"YOONGEE","userId":"13265385226373116446"}},"outputId":"69260316-f83f-452e-ed22-e46e2442e40c"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-11-720fbe55179b>:37: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  agg = pts.groupby('MMSI', group_keys=False).apply(_agg).reset_index()\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["✅ Submission saved to /content/drive/MyDrive/25년 해군 AI 경진대회/model_result/submission_ver4model.csv\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"gGpcTN8YaKh_"},"execution_count":null,"outputs":[]}]}